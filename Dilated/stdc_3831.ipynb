{"cells":[{"cell_type":"markdown","metadata":{"id":"Oc4QzK2lMdkH"},"source":["# STDC with dilations"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13898,"status":"ok","timestamp":1650266272189,"user":{"displayName":"Maxim Dobrokhvalov","userId":"05960264113093771023"},"user_tz":-180},"id":"IrFsKEKW7429","outputId":"fd1e89a4-df7f-4fdc-a830-75e655ca5464"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting tensorboardX\n","  Downloading tensorboardX-2.5-py2.py3-none-any.whl (125 kB)\n","\u001b[?25l\r\u001b[K     |██▋                             | 10 kB 21.9 MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 20 kB 12.3 MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 30 kB 9.0 MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 40 kB 7.9 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 51 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 61 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 71 kB 5.6 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 81 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 92 kB 6.0 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 102 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 112 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 122 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 125 kB 5.5 MB/s \n","\u001b[?25hRequirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorboardX) (3.17.3)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from tensorboardX) (1.15.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from tensorboardX) (1.21.5)\n","Installing collected packages: tensorboardX\n","Successfully installed tensorboardX-2.5\n"]}],"source":["import sys\n","sys.path.insert(0, '.')\n","import os\n","import logging\n","import random\n","import time\n","import math\n","import torch\n","import numpy as np \n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","from torch.nn import init\n","from torch.utils import data\n","from datetime import datetime, timedelta\n","from collections import OrderedDict\n","\n","from torchsummary import summary\n","\n","import torch.distributed as dist\n","\n"," \n","!pip install tensorboardX\n","from tensorboardX import SummaryWriter"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZvH1JPHzSxXK"},"outputs":[],"source":["os.environ['CUDA_LAUNCH_BLOCKING'] = '1'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_yTqA_v7SK42"},"outputs":[],"source":["batch_size = 8\n","n_workers = 2\n","print_interval=10\n","val_interval=500\n","\n","n_classes = 19\n","\n","model_arch = 'STDC_dilated'\n","\n","\n","bn_mom = 0.1\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BdAvR6h_Y43C"},"outputs":[],"source":["# Setup device\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"]},{"cell_type":"markdown","metadata":{"id":"_rlqCnjINmRs"},"source":["---\n","## Architecture"]},{"cell_type":"markdown","metadata":{"id":"ej7GwMiBroOM"},"source":["### Blocks"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IfQMxl1EysQu"},"outputs":[],"source":["class DilatedConv(nn.Module):\n","    def __init__(self, in_planes, out_planes, kernel_size=3, dilation=1, stride=1, bias=False):\n","        super().__init__()\n","        num_splits = 2\n","        # print(\"1\", out_planes, num_splits)\n","        assert(out_planes%num_splits == 0)\n","        conv_in_planes = in_planes // num_splits\n","        conv_out_planes = out_planes // num_splits\n","        # print(\"2\", conv_out_planes, group_width)\n","        # assert(conv_out_planes%group_width == 0)\n","        # ------------------\n","        # TODO: change groups count\n","        # groups = conv_out_planes // group_width\n","        groups = 2\n","        conv_1 = nn.Conv2d(conv_in_planes, conv_out_planes, kernel_size, padding=kernel_size//2, dilation=1, stride=stride, groups=groups, bias=bias)\n","        conv_n = nn.Conv2d(conv_in_planes, conv_out_planes, 3, padding=dilation, dilation=dilation, stride=stride, groups=groups, bias=bias)\n","        self.convs=nn.ModuleList([conv_1, conv_n])\n","        self.num_splits=num_splits\n","        self.init_weight()\n","    \n","    def forward(self,x):\n","        x=torch.tensor_split(x,self.num_splits,dim=1)\n","        res = []\n","        for i in range(self.num_splits):\n","            res.append(self.convs[i](x[i]))\n","        return torch.cat(res,dim=1)\n","    \n","    def init_weight(self):\n","        for ly in self.children():\n","            if isinstance(ly, nn.Conv2d):\n","                nn.init.kaiming_normal_(ly.weight, a=1)\n","                if not ly.bias is None: nn.init.constant_(ly.bias, 0)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VehqKGzJyoV9"},"outputs":[],"source":["class ConvX(nn.Module):\n","    def __init__(self, in_planes, out_planes, kernel=3, stride=1, dilation=1):\n","        super(ConvX, self).__init__()\n","        \n","        if dilation == 1:\n","            self.conv = nn.Conv2d(in_planes, out_planes, kernel_size=kernel, stride=stride, padding=kernel//2, bias=False)\n","        else:\n","            self.conv = DilatedConv(in_planes, out_planes, kernel_size=kernel, stride=stride, dilation=dilation, bias=False)\n","        self.bn = nn.BatchNorm2d(out_planes)\n","        self.relu = nn.ReLU(inplace=True)\n","        self.init_weight()\n","\n","    def forward(self, x):\n","        out = self.relu(self.bn(self.conv(x)))\n","        return out\n","\n","    def init_weight(self):\n","        for ly in self.children():\n","            if isinstance(ly, nn.Conv2d):\n","                nn.init.kaiming_normal_(ly.weight, a=1)\n","                if not ly.bias is None: nn.init.constant_(ly.bias, 0)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gwHZ02vWozj0"},"outputs":[],"source":["class CatBottleneck(nn.Module):\n","    def __init__(self, in_planes, out_planes, block_num=4, stride=1, dilation=1):\n","        super(CatBottleneck, self).__init__()\n","        assert block_num > 1, print(\"block number should be larger than 1.\")\n","        self.conv_list = nn.ModuleList()\n","        self.stride = stride\n","        if stride == 2:\n","            self.avd_layer = nn.Sequential(\n","                nn.Conv2d(out_planes//2, out_planes//2, kernel_size=3, stride=2, padding=1, groups=out_planes//2, bias=False),\n","                nn.BatchNorm2d(out_planes//2),\n","            )\n","            self.skip = nn.AvgPool2d(kernel_size=3, stride=2, padding=1)\n","            stride = 1\n","\n","        for idx in range(block_num):\n","            blk = None\n","            if idx == 0:\n","                blk = ConvX(in_planes, out_planes//2, kernel=1)\n","            elif idx == 1 and block_num == 2:\n","                blk = ConvX(out_planes//2, out_planes//2, stride=stride, dilation=dilation)\n","            elif idx == 1 and block_num > 2:\n","                blk = ConvX(out_planes//2, out_planes//4, stride=stride, dilation=dilation)\n","            elif idx < block_num - 1:\n","                blk = ConvX(out_planes//int(math.pow(2, idx)), out_planes//int(math.pow(2, idx+1)), dilation=dilation)\n","            else:\n","                blk = ConvX(out_planes//int(math.pow(2, idx)), out_planes//int(math.pow(2, idx)), dilation=dilation)\n","            self.conv_list.append(blk)\n","            \n","    def forward(self, x):\n","        out_list = []\n","        out1 = self.conv_list[0](x)\n","\n","        for idx, conv in enumerate(self.conv_list[1:]):\n","            if idx == 0:\n","                if self.stride == 2:\n","                    out = conv(self.avd_layer(out1))\n","                else:\n","                    out = conv(out1)\n","            else:\n","                out = conv(out)\n","            out_list.append(out)\n","\n","        if self.stride == 2:\n","            out1 = self.skip(out1)\n","        out_list.insert(0, out1)\n","\n","        out = torch.cat(out_list, dim=1)\n","        return out"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OIqdvmi-yzg4"},"outputs":[],"source":["class BiSeNetOutput(nn.Module):\n","    def __init__(self, in_chan, mid_chan, n_classes, *args, **kwargs):\n","        super(BiSeNetOutput, self).__init__()\n","        self.conv = ConvX(in_chan, mid_chan, kernel=3, stride=1)\n","        self.conv_out = nn.Conv2d(mid_chan, n_classes, kernel_size=1, bias=False)\n","        self.init_weight()\n","\n","    def forward(self, x):\n","        x = self.conv(x)\n","        x = self.conv_out(x)\n","        return x\n","\n","    def init_weight(self):\n","        for ly in self.children():\n","            if isinstance(ly, nn.Conv2d):\n","                nn.init.kaiming_normal_(ly.weight, a=1)\n","                if not ly.bias is None: nn.init.constant_(ly.bias, 0)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NUHie9tesVSD"},"outputs":[],"source":["class Decoder(nn.Module):\n","    def __init__(self, num_classes, channels):\n","        super().__init__()\n","        channels4, channels8, channels16 = channels\n","        self.head16=ConvX(channels16, 128, 1)\n","        self.head8=ConvX(channels8, 128, 1)\n","        self.head4=ConvX(channels4, 8, 1)\n","        self.conv8=ConvX(128,64,3,1,1)\n","        self.conv4=ConvX(64+8,64,3,1,1)\n","        self.classifier=nn.Conv2d(64, num_classes, 1)\n","\n","    def forward(self, x):\n","        x4, x8, x16 = x\n","        x16=self.head16(x16)\n","        x8=self.head8(x8)\n","        x4=self.head4(x4)\n","        x16 = F.interpolate(x16, size=x8.shape[-2:], mode='bilinear', align_corners=False)\n","        x8= x8 + x16\n","        x8=self.conv8(x8)\n","        x8 = F.interpolate(x8, size=x4.shape[-2:], mode='bilinear', align_corners=False)\n","        x4=torch.cat((x8,x4),dim=1)\n","        x4=self.conv4(x4)\n","        x4=self.classifier(x4)\n","        return x4"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"88rzHfln70PP"},"outputs":[],"source":["class STDC_dilated(nn.Module):\n","    def __init__(self, blocks_dilation_and_stride = [], target_planes = 256, n_classes=19):\n","        super(STDC_dilated, self).__init__()\n","        self.conv0 = ConvX( 3, 32, kernel=3, stride=2)\n","        self.conv1 = ConvX(32, 64, kernel=3, stride=2)\n","        planes = 64\n","        blocks = []\n","        outs = []\n","        channels = []\n","        for i, block_info in enumerate(blocks_dilation_and_stride):\n","            dilation, stride = block_info\n","            in_planes = planes\n","            out_planes = planes\n","            if planes < target_planes:\n","                out_planes = min(out_planes * 2, target_planes)\n","                planes = out_planes\n","            \n","            blocks.append(CatBottleneck(in_planes, out_planes, dilation=dilation, stride=stride))\n","            if i == 0 or i ==len(blocks_dilation_and_stride)-1 or stride == 2:\n","                channels.append(out_planes)\n","                # outs.append(BiSeNetOutput(out_planes, 256, n_classes))\n","        self.blocks = nn.ModuleList(blocks)\n","        self.detail_out = BiSeNetOutput(channels[0], 64, 1)\n","        self.decoder = Decoder(19, channels[1:])\n","        # self.outs = nn.ModuleList(outs)\n","    \n","    def forward(self, x):\n","        out = self.conv0(x)\n","        out = self.conv1(out)\n","        store_out = []\n","        for i, module in enumerate(self.blocks):\n","            out = module(out)\n","            if i == 0 or i == len(self.blocks)-1 or module.stride == 2:\n","                # print(r.shape)\n","                # store_out.append(self.outs[len(store_out)](out))\n","                store_out.append(out)\n","        out_detail = self.detail_out(store_out[0])\n","        out = self.decoder(store_out[1:])\n","        out_detail = F.interpolate(out_detail, size=x.shape[-2:], mode='bilinear', align_corners=False)\n","        out = F.interpolate(out, size=x.shape[-2:], mode='bilinear', align_corners=False)\n","        return out, out_detail"]},{"cell_type":"markdown","metadata":{"id":"MfAtjams6ikd"},"source":["---\n","## Loss & Optimizer"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"x1X1GCpDNvej"},"outputs":[],"source":["class OhemCELoss(nn.Module):\n","    def __init__(self, thresh, n_min, ignore_lb=255, *args, **kwargs):\n","        super(OhemCELoss, self).__init__()\n","        self.thresh = -torch.log(torch.tensor(thresh, dtype=torch.float)).to(device)\n","        self.n_min = n_min\n","        self.ignore_lb = ignore_lb\n","        self.criteria = nn.CrossEntropyLoss(ignore_index=ignore_lb, reduction='none')\n","\n","    def forward(self, logits, labels):\n","        N, C, H, W = logits.size()\n","        loss = self.criteria(logits, labels).view(-1)\n","        loss, _ = torch.sort(loss, descending=True)\n","        if loss[self.n_min] > self.thresh:\n","            loss = loss[loss>self.thresh]\n","        else:\n","            loss = loss[:self.n_min]\n","        return torch.mean(loss)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3AtvMtbc_LfS"},"outputs":[],"source":["float_tensor_type = torch.cuda.FloatTensor if device.type=='cuda' else torch.FloatTensor"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Hxwvvyh6PdMg"},"outputs":[],"source":["def dice_loss_func(input, target):\n","    smooth = 1.\n","    n = input.size(0)\n","    iflat = input.view(n, -1)\n","    tflat = target.view(n, -1)\n","    intersection = (iflat * tflat).sum(1)\n","    loss = 1 - ((2. * intersection + smooth) /\n","                (iflat.sum(1) + tflat.sum(1) + smooth))\n","    return loss.mean()\n","\n","\n","class DetailAggregateLoss(nn.Module):\n","    def __init__(self, *args, **kwargs):\n","        super(DetailAggregateLoss, self).__init__()\n","        \n","        self.laplacian_kernel = torch.tensor(\n","            [-1, -1, -1, -1, 8, -1, -1, -1, -1],\n","            dtype=torch.float32).reshape(1, 1, 3, 3).requires_grad_(False).type(float_tensor_type)        \n","\n","        self.fuse_kernel = torch.nn.Parameter(torch.tensor([[6./10], [3./10], [1./10]],\n","            dtype=torch.float32).reshape(1, 3, 1, 1).type(float_tensor_type))\n","\n","    def forward(self, boundary_logits, gtmasks):\n","\n","        boundary_targets = F.conv2d(gtmasks.unsqueeze(1).type(float_tensor_type), self.laplacian_kernel, padding=1)\n","        boundary_targets = boundary_targets.clamp(min=0)\n","        boundary_targets[boundary_targets > 0.1] = 1\n","        boundary_targets[boundary_targets <= 0.1] = 0\n","\n","        boundary_targets_x2 = F.conv2d(gtmasks.unsqueeze(1).type(float_tensor_type), self.laplacian_kernel, stride=2, padding=1)\n","        boundary_targets_x2 = boundary_targets_x2.clamp(min=0)\n","        \n","        boundary_targets_x4 = F.conv2d(gtmasks.unsqueeze(1).type(float_tensor_type), self.laplacian_kernel, stride=4, padding=1)\n","        boundary_targets_x4 = boundary_targets_x4.clamp(min=0)\n","\n","        boundary_targets_x4_up = F.interpolate(boundary_targets_x4, boundary_targets.shape[2:], mode='nearest')\n","        boundary_targets_x2_up = F.interpolate(boundary_targets_x2, boundary_targets.shape[2:], mode='nearest')\n","        \n","        boundary_targets_x2_up[boundary_targets_x2_up > 0.1] = 1\n","        boundary_targets_x2_up[boundary_targets_x2_up <= 0.1] = 0\n","        \n","        \n","        boundary_targets_x4_up[boundary_targets_x4_up > 0.1] = 1\n","        boundary_targets_x4_up[boundary_targets_x4_up <= 0.1] = 0\n","       \n","        boudary_targets_pyramids = torch.stack((boundary_targets, boundary_targets_x2_up, boundary_targets_x4_up), dim=1)\n","        \n","        boudary_targets_pyramids = boudary_targets_pyramids.squeeze(2)\n","        boudary_targets_pyramid = F.conv2d(boudary_targets_pyramids, self.fuse_kernel)\n","\n","        boudary_targets_pyramid[boudary_targets_pyramid > 0.1] = 1\n","        boudary_targets_pyramid[boudary_targets_pyramid <= 0.1] = 0\n","        \n","        \n","        if boundary_logits.shape[-1] != boundary_targets.shape[-1]:\n","            boundary_logits = F.interpolate(\n","                boundary_logits, boundary_targets.shape[2:], mode='bilinear', align_corners=True)\n","        \n","        bce_loss = F.binary_cross_entropy_with_logits(boundary_logits, boudary_targets_pyramid)\n","        dice_loss = dice_loss_func(torch.sigmoid(boundary_logits), boudary_targets_pyramid)\n","        return bce_loss,  dice_loss\n","\n","    def get_params(self):\n","        wd_params, nowd_params = [], []\n","        for name, module in self.named_modules():\n","                nowd_params += list(module.parameters())\n","        return nowd_params"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OpE2HElyOJB3"},"outputs":[],"source":["class Optimizer(object):\n","    def __init__(self, model, loss, lr0, momentum, wd, warmup_steps, \n","                 warmup_start_lr, max_iter, power, *args, **kwargs):\n","        self.warmup_steps = warmup_steps\n","        self.warmup_start_lr = warmup_start_lr\n","        self.lr0 = lr0\n","        self.lr = self.lr0\n","        self.max_iter = float(max_iter)\n","        self.power = power\n","        self.it = 0\n","        # wd_params, nowd_params = model.get_params() # , lr_mul_wd_params, lr_mul_nowd_params\n","        loss_nowd_params = loss.get_params()\n","        #---------------------------------------------------------------------------\n","        #---------------------------------------------------------------------------\n","        #---------------------------------------------------------------------------\n","        param_list = [\n","                {'params': model.parameters()},\n","                {'params': loss_nowd_params}]\n","        self.optim = torch.optim.SGD(\n","                param_list,\n","                # model.parameters(),\n","                lr = lr0,\n","                momentum = momentum,\n","                weight_decay = wd)\n","        self.warmup_factor = (self.lr0/self.warmup_start_lr)**(1./self.warmup_steps)\n","\n","    def get_lr(self):\n","        if self.it <= self.warmup_steps:\n","            lr = self.warmup_start_lr*(self.warmup_factor**self.it)\n","        else:\n","            factor = (1-(self.it-self.warmup_steps)/(self.max_iter-self.warmup_steps))**self.power\n","            lr = self.lr0 * factor\n","        return lr\n","\n","    def step(self):\n","        self.lr = self.get_lr()\n","        for pg in self.optim.param_groups:\n","            if pg.get('lr_mul', False):\n","                pg['lr'] = self.lr * 10\n","            else:\n","                pg['lr'] = self.lr\n","        if self.optim.defaults.get('lr_mul', False):\n","            self.optim.defaults['lr'] = self.lr * 10\n","        else:\n","            self.optim.defaults['lr'] = self.lr\n","        self.it += 1\n","        self.optim.step()\n","        if self.it == self.warmup_steps+2:\n","            logger.info('==> warmup done, start to implement poly lr strategy')\n","    \n","    def get_state(self):\n","        return {\n","            'warmup_steps': self.warmup_steps,\n","            'warmup_start_lr': self.warmup_start_lr,\n","            'lr0': self.lr0,\n","            'lr': self.lr,\n","            'max_iter': self.max_iter,\n","            'power': self.power, \n","            'it': self.it,\n","            'optim_state': self.optim.state_dict(),\n","            'warmup_factor': self.warmup_factor\n","        }\n","\n","    def load_state(self, state):\n","        self.warmup_steps = state.get('warmup_steps')\n","        self.warmup_start_lr = state.get('warmup_start_lr')\n","        self.lr0 = state.get('lr0')\n","        self.lr = state.get('lr')\n","        self.max_iter = state.get('max_iter')\n","        self.power = state.get('power')\n","        self.it = state.get('it')\n","        self.optim.load_state_dict(state.get('optim_state'))\n","        self.warmup_factor = state.get('warmup_factor')\n","\n","\n","    def zero_grad(self):\n","        self.optim.zero_grad()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"L-4mDzEJUx7x"},"outputs":[],"source":["score_thres = 0.7\n","n_img_per_gpu = 8\n","cropsize = (512, 1024)\n","n_min = n_img_per_gpu*cropsize[0]*cropsize[1]//32\n","ignore_idx=255"]},{"cell_type":"markdown","metadata":{"id":"o-tF2L-AXDcn"},"source":["---\n","## Dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":272,"status":"ok","timestamp":1650266273094,"user":{"displayName":"Maxim Dobrokhvalov","userId":"05960264113093771023"},"user_tz":-180},"id":"rUhwVh6gXReD","outputId":"992111ef-a776-4cb6-8cd3-de2e915da882"},"outputs":[{"output_type":"stream","name":"stdout","text":["--2022-04-18 07:17:52--  https://raw.githubusercontent.com/MichaelFan01/STDC-Seg/master/cityscapes_info.json\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.111.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 7412 (7.2K) [text/plain]\n","Saving to: ‘cityscapes_info.json’\n","\n","cityscapes_info.jso 100%[===================>]   7.24K  --.-KB/s    in 0s      \n","\n","2022-04-18 07:17:52 (76.2 MB/s) - ‘cityscapes_info.json’ saved [7412/7412]\n","\n"]}],"source":["!wget https://raw.githubusercontent.com/MichaelFan01/STDC-Seg/master/cityscapes_info.json"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_hLh2hCJPJsj"},"outputs":[],"source":["from PIL import Image\n","import PIL.ImageEnhance as ImageEnhance\n","import random\n","import numpy as np\n","\n","\n","class RandomCrop(object):\n","    def __init__(self, size, *args, **kwargs):\n","        self.size = size\n","\n","    def __call__(self, im_lb):\n","        im = im_lb['im']\n","        lb = im_lb['lb']\n","        assert im.size == lb.size\n","        W, H = self.size\n","        w, h = im.size\n","\n","        if (W, H) == (w, h): return dict(im=im, lb=lb)\n","        if w < W or h < H:\n","            scale = float(W) / w if w < h else float(H) / h\n","            w, h = int(scale * w + 1), int(scale * h + 1)\n","            im = im.resize((w, h), Image.BILINEAR)\n","            lb = lb.resize((w, h), Image.NEAREST)\n","        sw, sh = random.random() * (w - W), random.random() * (h - H)\n","        crop = int(sw), int(sh), int(sw) + W, int(sh) + H\n","        return dict(\n","                im = im.crop(crop),\n","                lb = lb.crop(crop)\n","                    )\n","\n","\n","class HorizontalFlip(object):\n","    def __init__(self, p=0.5, *args, **kwargs):\n","        self.p = p\n","\n","    def __call__(self, im_lb):\n","        if random.random() > self.p:\n","            return im_lb\n","        else:\n","            im = im_lb['im']\n","            lb = im_lb['lb']\n","            return dict(im = im.transpose(Image.FLIP_LEFT_RIGHT),\n","                        lb = lb.transpose(Image.FLIP_LEFT_RIGHT),\n","                    )\n","\n","\n","class RandomScale(object):\n","    def __init__(self, scales=(1, ), *args, **kwargs):\n","        self.scales = scales\n","        # print('scales: ', scales)\n","\n","    def __call__(self, im_lb):\n","        im = im_lb['im']\n","        lb = im_lb['lb']\n","        W, H = im.size\n","        scale = random.choice(self.scales)\n","        # scale = np.random.uniform(min(self.scales), max(self.scales))\n","        w, h = int(W * scale), int(H * scale)\n","        return dict(im = im.resize((w, h), Image.BILINEAR),\n","                    lb = lb.resize((w, h), Image.NEAREST),\n","                )\n","\n","\n","class ColorJitter(object):\n","    def __init__(self, brightness=None, contrast=None, saturation=None, *args, **kwargs):\n","        if not brightness is None and brightness>0:\n","            self.brightness = [max(1-brightness, 0), 1+brightness]\n","        if not contrast is None and contrast>0:\n","            self.contrast = [max(1-contrast, 0), 1+contrast]\n","        if not saturation is None and saturation>0:\n","            self.saturation = [max(1-saturation, 0), 1+saturation]\n","\n","    def __call__(self, im_lb):\n","        im = im_lb['im']\n","        lb = im_lb['lb']\n","        r_brightness = random.uniform(self.brightness[0], self.brightness[1])\n","        r_contrast = random.uniform(self.contrast[0], self.contrast[1])\n","        r_saturation = random.uniform(self.saturation[0], self.saturation[1])\n","        im = ImageEnhance.Brightness(im).enhance(r_brightness)\n","        im = ImageEnhance.Contrast(im).enhance(r_contrast)\n","        im = ImageEnhance.Color(im).enhance(r_saturation)\n","        return dict(im = im,\n","                    lb = lb,\n","                )\n","\n","\n","class MultiScale(object):\n","    def __init__(self, scales):\n","        self.scales = scales\n","\n","    def __call__(self, img):\n","        W, H = img.size\n","        sizes = [(int(W*ratio), int(H*ratio)) for ratio in self.scales]\n","        imgs = []\n","        [imgs.append(img.resize(size, Image.BILINEAR)) for size in sizes]\n","        return imgs\n","\n","\n","class Compose(object):\n","    def __init__(self, do_list):\n","        self.do_list = do_list\n","\n","    def __call__(self, im_lb):\n","        for comp in self.do_list:\n","            im_lb = comp(im_lb)\n","        return im_lb"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"c88kJt45PP93"},"outputs":[],"source":["import torch\n","from torch.utils.data import Dataset, DataLoader\n","import torchvision.transforms as transforms\n","\n","import os.path as osp\n","import os\n","from PIL import Image\n","import numpy as np\n","import json\n","\n","\n","\n","class CityScapes(Dataset):\n","    def __init__(self, rootpth, cropsize=(640, 480), mode='train', \n","    randomscale=(0.125, 0.25, 0.375, 0.5, 0.675, 0.75, 0.875, 1.0, 1.25, 1.5), *args, **kwargs):\n","        super(CityScapes, self).__init__(*args, **kwargs)\n","        assert mode in ('train', 'val', 'test', 'trainval')\n","        self.mode = mode\n","        print('self.mode', self.mode)\n","        self.ignore_lb = 255\n","\n","        with open('./cityscapes_info.json', 'r') as fr:\n","            labels_info = json.load(fr)\n","        self.lb_map = {el['id']: el['trainId'] for el in labels_info}\n","        \n","\n","        ## parse img directory\n","        self.imgs = {}\n","        imgnames = []\n","        impth = osp.join(rootpth, 'leftImg8bit', mode)\n","        folders = os.listdir(impth)\n","        for fd in folders:\n","            fdpth = osp.join(impth, fd)\n","            im_names = os.listdir(fdpth)\n","            names = [el.replace('_leftImg8bit.png', '') for el in im_names]\n","            impths = [osp.join(fdpth, el) for el in im_names]\n","            imgnames.extend(names)\n","            self.imgs.update(dict(zip(names, impths)))\n","\n","        ## parse gt directory\n","        self.labels = {}\n","        gtnames = []\n","        gtpth = osp.join(rootpth, 'gtFine', mode)\n","        folders = os.listdir(gtpth)\n","        for fd in folders:\n","            fdpth = osp.join(gtpth, fd)\n","            lbnames = os.listdir(fdpth)\n","            lbnames = [el for el in lbnames if 'labelIds' in el]\n","            names = [el.replace('_gtFine_labelIds.png', '') for el in lbnames]\n","            lbpths = [osp.join(fdpth, el) for el in lbnames]\n","            gtnames.extend(names)\n","            self.labels.update(dict(zip(names, lbpths)))\n","\n","        self.imnames = imgnames\n","        self.len = len(self.imnames)\n","        print('self.len', self.mode, self.len)\n","        assert set(imgnames) == set(gtnames)\n","        assert set(self.imnames) == set(self.imgs.keys())\n","        assert set(self.imnames) == set(self.labels.keys())\n","\n","        ## pre-processing\n","        self.to_tensor = transforms.Compose([\n","            transforms.ToTensor(),\n","            transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n","            ])\n","        self.trans_train = Compose([\n","            ColorJitter(\n","                brightness = 0.5,\n","                contrast = 0.5,\n","                saturation = 0.5),\n","            HorizontalFlip(),\n","            RandomScale(randomscale),\n","            RandomCrop(cropsize)\n","            ])\n","\n","\n","    def __getitem__(self, idx):\n","        fn  = self.imnames[idx]\n","        impth = self.imgs[fn]\n","        lbpth = self.labels[fn]\n","        img = Image.open(impth).convert('RGB')\n","        label = Image.open(lbpth)\n","        if self.mode == 'train' or self.mode == 'trainval':\n","            im_lb = dict(im = img, lb = label)\n","            im_lb = self.trans_train(im_lb)\n","            img, label = im_lb['im'], im_lb['lb']\n","        img = self.to_tensor(img)\n","        label = np.array(label).astype(np.int64)[np.newaxis, :]\n","        label = self.convert_labels(label)\n","        return img, label\n","\n","\n","    def __len__(self):\n","        return self.len\n","\n","\n","    def convert_labels(self, label):\n","        for k, v in self.lb_map.items():\n","            label[label == k] = v\n","        return label"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":25840,"status":"ok","timestamp":1650266299505,"user":{"displayName":"Maxim Dobrokhvalov","userId":"05960264113093771023"},"user_tz":-180},"id":"CdTbxumgrAqo","outputId":"cf99ca9e-b1ee-417b-a57e-9892cf12fc07"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"87f6J6wdXxpA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1650266326691,"user_tz":-180,"elapsed":27207,"user":{"displayName":"Maxim Dobrokhvalov","userId":"05960264113093771023"}},"outputId":"a85ddc72-d6d8-431c-826b-193d0acc6917"},"outputs":[{"output_type":"stream","name":"stdout","text":["self.mode train\n","self.len train 2975\n","self.mode val\n","self.len val 500\n"]}],"source":["dspth = '/content/drive/MyDrive/RnD/datasets/'\n","cfg_data = {\n","    'dataset': 'cityscapes',\n","    'train_split': 'train',\n","    'val_split': 'val',\n","    'img_rows': cropsize[0],\n","    'img_cols': cropsize[1],\n","    'path': dspth\n","}\n","randomscale = (0.125, 0.25, 0.375, 0.5, 0.625, 0.75, 0.875, 1.0, 1.125, 1.25, 1.375, 1.5)\n","ds = CityScapes(cfg_data['path'], cropsize=cropsize, mode='train', randomscale=randomscale)\n","# sampler = torch.utils.data.distributed.DistributedSampler(ds)\n","dl = DataLoader(ds,\n","                batch_size = batch_size,\n","                shuffle = False,\n","                # sampler = sampler,\n","                num_workers = n_workers,\n","                pin_memory = False,\n","                drop_last = True)\n","# exit(0)\n","dsval = CityScapes(cfg_data['path'], mode='val', randomscale=randomscale)\n","# sampler_val = torch.utils.data.distributed.DistributedSampler(dsval)\n","dlval = DataLoader(dsval,\n","                batch_size = 2,\n","                shuffle = False,\n","                # sampler = sampler_val,\n","                num_workers = n_workers,\n","                drop_last = False)\n","\n","## model\n","ignore_idx = 255"]},{"cell_type":"markdown","metadata":{"id":"csU-R0brNqti"},"source":["---\n","# Preparing for train"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"q_MVKWyjNwFH"},"outputs":[],"source":["best_iou = -100.0\n","loss_all = 0\n","loss_n = 0"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2GqMaMb8PBiV"},"outputs":[],"source":["def get_logger(logdir):\n","    logger = logging.getLogger(\"DR_test\")\n","    ts = str(datetime.now()).split(\".\")[0].replace(\" \", \"_\")\n","    ts = ts.replace(\":\", \"_\").replace(\"-\", \"_\")\n","    file_path = os.path.join(logdir, \"run_{}.log\".format(ts))\n","    hdlr = logging.FileHandler(file_path)\n","    formatter = logging.Formatter(\"%(asctime)s %(levelname)s %(message)s\")\n","    hdlr.setFormatter(formatter)\n","    logger.addHandler(hdlr)\n","    logger.setLevel(logging.INFO)\n","    return logger"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OCjt4GHxQV-S","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1650266328006,"user_tz":-180,"elapsed":1349,"user":{"displayName":"Maxim Dobrokhvalov","userId":"05960264113093771023"}},"outputId":"35c5095e-3c9a-4e62-ac9e-534975577d03"},"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'FCHarDNet'...\n","remote: Enumerating objects: 130, done.\u001b[K\n","remote: Counting objects: 100% (13/13), done.\u001b[K\n","remote: Compressing objects: 100% (12/12), done.\u001b[K\n","remote: Total 130 (delta 2), reused 7 (delta 1), pack-reused 117\u001b[K\n","Receiving objects: 100% (130/130), 9.10 MiB | 23.47 MiB/s, done.\n","Resolving deltas: 100% (50/50), done.\n"]}],"source":["!git clone https://github.com/PingoLH/FCHarDNet.git\n","!cp -r FCHarDNet/ptsemseg ./\n","!rm -rf FCHarDNet"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2-4aOn4dQeLT"},"outputs":[],"source":["from ptsemseg.metrics import runningScore, averageMeter"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nJTlBpSmStgU"},"outputs":[],"source":["base_path = \"/content/drive/MyDrive/RnD/runs/STDC\"\n","model_modification = 'STDC_dilated_fov_3831'\n","model_modification_path = os.path.join(base_path, model_modification)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TAoSxPyeaFio","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1650266328664,"user_tz":-180,"elapsed":660,"user":{"displayName":"Maxim Dobrokhvalov","userId":"05960264113093771023"}},"outputId":"616e10dd-d4db-4b46-a019-13cf142e215e"},"outputs":[{"output_type":"stream","name":"stdout","text":["RUNDIR: /content/drive/MyDrive/RnD/runs/STDC/STDC_dilated_fov_3831/2022-04-18 07:18:47\n"]}],"source":["logdir = os.path.join(model_modification_path, str(datetime.fromtimestamp(int(time.time()))))\n","writer = SummaryWriter(log_dir=logdir)\n","\n","print(\"RUNDIR: {}\".format(logdir))\n","\n","logger = get_logger(logdir)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nDPzLJpLP7au"},"outputs":[],"source":["# Setup seeds\n","# torch.manual_seed(1337)\n","# torch.cuda.manual_seed(1337)\n","# np.random.seed(1337)\n","# random.seed(1337)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"G95g0arBR1AY"},"outputs":[],"source":["running_metrics_val = runningScore(n_classes)\n","\n","init = [(1, 1), (1, 1), (2, 2), (2, 1), (4, 2), (4, 1), (8, 1), (12, 1)]\n","model = STDC_dilated(init)\n","\n","def weights_init(m):\n","    if isinstance(m, nn.Conv2d):\n","        nn.init.xavier_normal_(m.weight)\n","\n","model = torch.nn.DataParallel(model, device_ids=range(torch.cuda.device_count()))\n","model.apply(weights_init)\n","pass"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"P_5wFQ0UVnHt"},"outputs":[],"source":["# optimizer init data\n","momentum = 0.9\n","weight_decay = 5e-4\n","lr_start = 1e-2\n","power = 0.9\n","warmup_steps = 1000\n","warmup_start_lr = 1e-5\n","epoch_iteration = len(ds) // batch_size\n","max_epoch = 1000\n","max_iter = max_epoch * epoch_iteration"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rg_faMQHOnMZ"},"outputs":[],"source":["start_epoch = 0\n","it = 0\n","local_max_epoch = start_epoch + 6 if start_epoch + 6 < max_epoch else max_epoch"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nfsksqZNg3TM"},"outputs":[],"source":["criteria_ffm = OhemCELoss(thresh=score_thres, n_min=n_min, ignore_lb=ignore_idx)    # out1\n","boundary_loss_func = DetailAggregateLoss()                                          # out3\n","criteria_val = OhemCELoss(thresh=score_thres, n_min=n_min, ignore_lb=ignore_idx)    # out1 \n","val_loss_meter = averageMeter()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SFawk_jCVuJg"},"outputs":[],"source":["optim = Optimizer(\n","            model = model.module,\n","            loss = boundary_loss_func,\n","            lr0 = lr_start,\n","            momentum = momentum,\n","            wd = weight_decay,\n","            warmup_steps = warmup_steps,\n","            warmup_start_lr = warmup_start_lr,\n","            max_iter = max_iter,\n","            power = power)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gcCTdTNiWhH3"},"outputs":[],"source":["loss_avg = []\n","loss_boundery_bce = []\n","loss_boundery_dice = []"]},{"cell_type":"markdown","metadata":{"id":"2aFTxfMXSqw3"},"source":["---\n","## Restore state"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kuw_ClrzSqJM"},"outputs":[],"source":["runs = sorted(os.listdir(model_modification_path), reverse=True)\n","best_path = None\n","last_path = None\n","for run in runs:\n","    tmp_base = os.path.join(model_modification_path, run)\n","    model_name = \"{}_{}\".format(model_arch, cfg_data['dataset'])\n","    checkpoint = os.path.join(tmp_base, model_name+'_checkpoint.pkl')\n","    best = os.path.join(tmp_base, model_name+'_best_model.pkl')\n","    if not last_path and os.path.exists(checkpoint):\n","        last_path = checkpoint\n","    if not best_path and os.path.exists(best):\n","        best_path = best\n","    if last_path and best_path:\n","        break"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1jc6LeN9TOCq"},"outputs":[],"source":["loaded = torch.load(last_path)\n","best_iou_arrc = torch.load(best_path)\n","model_state = loaded.get('model_state')\n","\n","optimizer_state = loaded.get('optimizer_state')\n","start_epoch = loaded.get('epoch') + 1\n","local_max_epoch = start_epoch + 12\n","\n","best_iou = best_iou_arrc.get('best_iou')\n","i = 0\n","not_yet_run_in_session = True\n","loss_all = 0\n","loss_n = 0\n","\n","model.load_state_dict(model_state)\n","optim.load_state(optimizer_state)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"e4HbAmnvVMFA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1650278489740,"user_tz":-180,"elapsed":29,"user":{"displayName":"Maxim Dobrokhvalov","userId":"05960264113093771023"}},"outputId":"e25fb5b7-0661-4969-c7d9-acf6c4f6ed32"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(114, 120, 0.5205275776674654)"]},"metadata":{},"execution_count":38}],"source":["file_ = list(filter(lambda x: x.endswith('.log'), os.listdir(logdir)))[0]\n","file_ = os.path.join(logdir, file_)\n","if not not_yet_run_in_session and osp.isfile(file_):\n","    with open(file_, \"r\") as f:\n","        str_ = f.readlines()[-24]\n","        st__, end__ = str_.find('Epoch') + 6, str_.find(' Iter')\n","        if st__ > -1 and end__ > -1 and local_max_epoch - 1 == int(str_[st__:end__]):\n","            start_epoch = local_max_epoch\n","            local_max_epoch += 6\n","\n","\n","start_epoch, local_max_epoch, best_iou"]},{"cell_type":"markdown","metadata":{"id":"1ZjxXbpI_MDX"},"source":["## Training"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HuAUlVp7XTSc","outputId":"a45c492e-a117-4658-c180-e5e9e04c48da","executionInfo":{"status":"ok","timestamp":1650278488493,"user_tz":-180,"elapsed":12137055,"user":{"displayName":"Maxim Dobrokhvalov","userId":"05960264113093771023"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["loss/train_loss 1.9219645261764526 10\n","loss/train_loss 1.6109199523925781 20\n","loss/train_loss 1.8759407997131348 30\n","loss/train_loss 1.910866379737854 40\n","loss/train_loss 2.0351948738098145 50\n","loss/train_loss 2.389827013015747 60\n","loss/train_loss 1.767991304397583 70\n","loss/train_loss 1.593602180480957 80\n","loss/train_loss 1.6778604984283447 90\n","loss/train_loss 1.9181208610534668 100\n","loss/train_loss 1.7625142335891724 110\n","loss/train_loss 1.9059603214263916 120\n","loss/train_loss 1.9251569509506226 130\n","loss/train_loss 1.6615791320800781 140\n","loss/train_loss 1.960301160812378 150\n","loss/train_loss 1.8397976160049438 160\n","loss/train_loss 1.813936710357666 170\n","loss/train_loss 1.9715975522994995 180\n","loss/train_loss 1.7540433406829834 190\n","loss/train_loss 1.8633942604064941 200\n","loss/train_loss 1.8112359046936035 210\n","loss/train_loss 2.106586217880249 220\n","loss/train_loss 1.7116589546203613 230\n","loss/train_loss 1.589247226715088 240\n","loss/train_loss 1.8746438026428223 250\n","loss/train_loss 1.7237534523010254 260\n","loss/train_loss 1.7673207521438599 270\n","loss/train_loss 1.7881070375442505 280\n","loss/train_loss 2.029654026031494 290\n","loss/train_loss 1.8963322639465332 300\n","loss/train_loss 1.8193005323410034 310\n","loss/train_loss 1.77187180519104 320\n","loss/train_loss 1.907210111618042 330\n","loss/train_loss 1.722222089767456 340\n","loss/train_loss 2.906704902648926 350\n","loss/train_loss 1.7399476766586304 360\n","loss/train_loss 1.5992755889892578 370\n","validation\n","50\n","100\n","150\n","200\n","250\n","loss/val_loss 1.1311629650592805 371\n","Overall Acc: \t 0.9070897631596172\n","val_metrics/Overall Acc: \t 0.9070897631596172 371\n","Mean Acc : \t 0.5789658141059563\n","val_metrics/Mean Acc : \t 0.5789658141059563 371\n","FreqW Acc : \t 0.8424948072625167\n","val_metrics/FreqW Acc : \t 0.8424948072625167 371\n","Mean IoU : \t 0.473348100094861\n","val_metrics/Mean IoU : \t 0.473348100094861 371\n","val_metrics/cls_0 0.958664614811769 371\n","val_metrics/cls_1 0.7066955250006826 371\n","val_metrics/cls_2 0.8277114746568945 371\n","val_metrics/cls_3 0.17936133575815896 371\n","val_metrics/cls_4 0.29149314900699863 371\n","val_metrics/cls_5 0.3996904576774198 371\n","val_metrics/cls_6 0.35849802486998805 371\n","val_metrics/cls_7 0.4144756145719979 371\n","val_metrics/cls_8 0.8498797454648882 371\n","val_metrics/cls_9 0.4545833386283367 371\n","val_metrics/cls_10 0.8903205701277566 371\n","val_metrics/cls_11 0.5516294877711369 371\n","val_metrics/cls_12 0.10639472325193969 371\n","val_metrics/cls_13 0.8493678127121611 371\n","val_metrics/cls_14 0.15586759947668707 371\n","val_metrics/cls_15 0.4508654465934533 371\n","val_metrics/cls_16 0.11646187399930585 371\n","val_metrics/cls_17 0.028693232078117203 371\n","val_metrics/cls_18 0.4029598753446663 371\n","loss/train_loss 2.2444446086883545 10\n","loss/train_loss 1.9646713733673096 20\n","loss/train_loss 1.9835076332092285 30\n","loss/train_loss 1.8579494953155518 40\n","loss/train_loss 1.8985693454742432 50\n","loss/train_loss 1.9082527160644531 60\n","loss/train_loss 1.9886584281921387 70\n","loss/train_loss 1.7660496234893799 80\n","loss/train_loss 1.6700899600982666 90\n","loss/train_loss 1.767392635345459 100\n","loss/train_loss 1.9982985258102417 110\n","loss/train_loss 1.8062748908996582 120\n","loss/train_loss 1.7255192995071411 130\n","loss/train_loss 1.789596676826477 140\n","loss/train_loss 1.884874701499939 150\n","loss/train_loss 1.9511044025421143 160\n","loss/train_loss 1.8929755687713623 170\n","loss/train_loss 1.9453306198120117 180\n","loss/train_loss 1.7644940614700317 190\n","loss/train_loss 1.9259374141693115 200\n","loss/train_loss 1.8005342483520508 210\n","loss/train_loss 2.0079445838928223 220\n","loss/train_loss 1.829313039779663 230\n","loss/train_loss 1.7262816429138184 240\n","loss/train_loss 2.064380645751953 250\n","loss/train_loss 1.9965083599090576 260\n","loss/train_loss 1.667729139328003 270\n","loss/train_loss 2.1024844646453857 280\n","loss/train_loss 2.0668234825134277 290\n","loss/train_loss 1.8681714534759521 300\n","loss/train_loss 1.878028154373169 310\n","loss/train_loss 2.026580810546875 320\n","loss/train_loss 2.0687222480773926 330\n","loss/train_loss 1.844506859779358 340\n","loss/train_loss 1.7373592853546143 350\n","loss/train_loss 1.824099063873291 360\n","loss/train_loss 1.7106115818023682 370\n","validation\n","50\n","100\n","150\n","200\n","250\n","loss/val_loss 1.1326091220378876 371\n","Overall Acc: \t 0.8821690235299061\n","val_metrics/Overall Acc: \t 0.8821690235299061 371\n","Mean Acc : \t 0.5722719076804873\n","val_metrics/Mean Acc : \t 0.5722719076804873 371\n","FreqW Acc : \t 0.8096558975208479\n","val_metrics/FreqW Acc : \t 0.8096558975208479 371\n","Mean IoU : \t 0.4459711565617386\n","val_metrics/Mean IoU : \t 0.4459711565617386 371\n","val_metrics/cls_0 0.9413258070151461 371\n","val_metrics/cls_1 0.6347916330966406 371\n","val_metrics/cls_2 0.7995314171542321 371\n","val_metrics/cls_3 0.19361924954061074 371\n","val_metrics/cls_4 0.21771236708082853 371\n","val_metrics/cls_5 0.3752336600185386 371\n","val_metrics/cls_6 0.23637637916828216 371\n","val_metrics/cls_7 0.42406543879029657 371\n","val_metrics/cls_8 0.7907471419266665 371\n","val_metrics/cls_9 0.3850820108692842 371\n","val_metrics/cls_10 0.9090679541019544 371\n","val_metrics/cls_11 0.5104830446062657 371\n","val_metrics/cls_12 0.1915296269516702 371\n","val_metrics/cls_13 0.7834987210400252 371\n","val_metrics/cls_14 0.047646026967258163 371\n","val_metrics/cls_15 0.4425211304639001 371\n","val_metrics/cls_16 0.13254834565548457 371\n","val_metrics/cls_17 0.06316412381956928 371\n","val_metrics/cls_18 0.39450789640637923 371\n","loss/train_loss 1.65704345703125 10\n","loss/train_loss 1.6796166896820068 20\n","loss/train_loss 2.1641504764556885 30\n","loss/train_loss 1.9173623323440552 40\n","loss/train_loss 1.9875205755233765 50\n","loss/train_loss 1.9888836145401 60\n","loss/train_loss 2.0003671646118164 70\n","loss/train_loss 1.8493112325668335 80\n","loss/train_loss 1.8546359539031982 90\n","loss/train_loss 1.6851909160614014 100\n","loss/train_loss 1.5368411540985107 110\n","loss/train_loss 1.8607827425003052 120\n","loss/train_loss 1.6860500574111938 130\n","loss/train_loss 1.6753166913986206 140\n","loss/train_loss 2.1529645919799805 150\n","loss/train_loss 1.7691490650177002 160\n","loss/train_loss 1.9454296827316284 170\n","loss/train_loss 2.519627094268799 180\n","loss/train_loss 1.7854840755462646 190\n","loss/train_loss 1.7305395603179932 200\n","loss/train_loss 1.7846291065216064 210\n","loss/train_loss 1.9673686027526855 220\n","loss/train_loss 1.644974946975708 230\n","loss/train_loss 1.931121587753296 240\n","loss/train_loss 2.1411352157592773 250\n","loss/train_loss 1.764870524406433 260\n","loss/train_loss 1.6226435899734497 270\n","loss/train_loss 1.9194530248641968 280\n","loss/train_loss 1.9248865842819214 290\n","loss/train_loss 2.0796494483947754 300\n","loss/train_loss 1.8667333126068115 310\n","loss/train_loss 1.906851053237915 320\n","loss/train_loss 2.366835594177246 330\n","loss/train_loss 1.6394145488739014 340\n","loss/train_loss 2.099485397338867 350\n","loss/train_loss 1.7585991621017456 360\n","loss/train_loss 1.7261661291122437 370\n","validation\n","50\n","100\n","150\n","200\n","250\n","loss/val_loss 1.0809430229663848 371\n","Overall Acc: \t 0.9155502719640367\n","val_metrics/Overall Acc: \t 0.9155502719640367 371\n","Mean Acc : \t 0.6191504847113422\n","val_metrics/Mean Acc : \t 0.6191504847113422 371\n","FreqW Acc : \t 0.8566307415585406\n","val_metrics/FreqW Acc : \t 0.8566307415585406 371\n","Mean IoU : \t 0.5205275776674654\n","val_metrics/Mean IoU : \t 0.5205275776674654 371\n","val_metrics/cls_0 0.9559546006755574 371\n","val_metrics/cls_1 0.6956376781453857 371\n","val_metrics/cls_2 0.8509848087400175 371\n","val_metrics/cls_3 0.22675562811552605 371\n","val_metrics/cls_4 0.27452939810275445 371\n","val_metrics/cls_5 0.4569871373151136 371\n","val_metrics/cls_6 0.4007683578061743 371\n","val_metrics/cls_7 0.5122971196110347 371\n","val_metrics/cls_8 0.8679866123431427 371\n","val_metrics/cls_9 0.46591962182801716 371\n","val_metrics/cls_10 0.9166193168329178 371\n","val_metrics/cls_11 0.6382901940845864 371\n","val_metrics/cls_12 0.22860876408275602 371\n","val_metrics/cls_13 0.8780645674816276 371\n","val_metrics/cls_14 0.12268068585703577 371\n","val_metrics/cls_15 0.499889688178179 371\n","val_metrics/cls_16 0.23632816883678312 371\n","val_metrics/cls_17 0.0868291848037112 371\n","val_metrics/cls_18 0.5748924428415227 371\n","loss/train_loss 1.7686164379119873 10\n","loss/train_loss 1.7029573917388916 20\n","loss/train_loss 1.8127317428588867 30\n","loss/train_loss 1.9596166610717773 40\n","loss/train_loss 1.6273255348205566 50\n","loss/train_loss 1.9689542055130005 60\n","loss/train_loss 1.752484917640686 70\n","loss/train_loss 1.8120521306991577 80\n","loss/train_loss 1.9546723365783691 90\n","loss/train_loss 1.7848237752914429 100\n","loss/train_loss 1.8767814636230469 110\n","loss/train_loss 1.892164945602417 120\n","loss/train_loss 1.6218905448913574 130\n","loss/train_loss 1.7636122703552246 140\n","loss/train_loss 1.8940306901931763 150\n","loss/train_loss 1.7961210012435913 160\n","loss/train_loss 1.8737735748291016 170\n","loss/train_loss 1.8815017938613892 180\n","loss/train_loss 1.8112807273864746 190\n","loss/train_loss 1.7893511056900024 200\n","loss/train_loss 1.6914393901824951 210\n","loss/train_loss 1.8147149085998535 220\n","loss/train_loss 1.8146110773086548 230\n","loss/train_loss 1.9063031673431396 240\n","loss/train_loss 2.18068790435791 250\n","loss/train_loss 1.7901325225830078 260\n","loss/train_loss 1.6938788890838623 270\n","loss/train_loss 1.886897325515747 280\n","loss/train_loss 1.9718337059020996 290\n","loss/train_loss 1.8457396030426025 300\n","loss/train_loss 1.7873456478118896 310\n","loss/train_loss 1.8893823623657227 320\n","loss/train_loss 2.028876781463623 330\n","loss/train_loss 1.7575442790985107 340\n","loss/train_loss 2.0610969066619873 350\n","loss/train_loss 1.8172527551651 360\n","loss/train_loss 1.8748815059661865 370\n","validation\n","50\n","100\n","150\n","200\n","250\n","loss/val_loss 1.108123339176178 371\n","Overall Acc: \t 0.9121871118565855\n","val_metrics/Overall Acc: \t 0.9121871118565855 371\n","Mean Acc : \t 0.5932720516102082\n","val_metrics/Mean Acc : \t 0.5932720516102082 371\n","FreqW Acc : \t 0.8514112499773053\n","val_metrics/FreqW Acc : \t 0.8514112499773053 371\n","Mean IoU : \t 0.48540494978621185\n","val_metrics/Mean IoU : \t 0.48540494978621185 371\n","val_metrics/cls_0 0.9548318624148029 371\n","val_metrics/cls_1 0.6797042644771639 371\n","val_metrics/cls_2 0.8492743892933019 371\n","val_metrics/cls_3 0.22989140286636195 371\n","val_metrics/cls_4 0.2949178345375519 371\n","val_metrics/cls_5 0.4587998735035624 371\n","val_metrics/cls_6 0.33454049093475025 371\n","val_metrics/cls_7 0.531476099317651 371\n","val_metrics/cls_8 0.863021366140746 371\n","val_metrics/cls_9 0.48627064388282065 371\n","val_metrics/cls_10 0.9022309307826367 371\n","val_metrics/cls_11 0.6024524138431646 371\n","val_metrics/cls_12 0.07053165097180508 371\n","val_metrics/cls_13 0.8736173605662009 371\n","val_metrics/cls_14 0.05160338095602936 371\n","val_metrics/cls_15 0.2682858680753158 371\n","val_metrics/cls_16 0.1852053029364391 371\n","val_metrics/cls_17 0.054571350712077464 371\n","val_metrics/cls_18 0.5314675597256441 371\n","loss/train_loss 2.216122627258301 10\n","loss/train_loss 1.67633056640625 20\n","loss/train_loss 1.8551862239837646 30\n","loss/train_loss 2.037156581878662 40\n","loss/train_loss 1.8065353631973267 50\n","loss/train_loss 1.8254411220550537 60\n","loss/train_loss 1.8728477954864502 70\n","loss/train_loss 1.5376787185668945 80\n","loss/train_loss 2.2367279529571533 90\n","loss/train_loss 1.6478168964385986 100\n","loss/train_loss 1.640077829360962 110\n","loss/train_loss 1.9491701126098633 120\n","loss/train_loss 1.757935881614685 130\n","loss/train_loss 1.6780091524124146 140\n","loss/train_loss 1.9891681671142578 150\n","loss/train_loss 1.856661081314087 160\n","loss/train_loss 1.8543701171875 170\n","loss/train_loss 1.754492163658142 180\n","loss/train_loss 1.8009734153747559 190\n","loss/train_loss 1.8610552549362183 200\n","loss/train_loss 1.7777807712554932 210\n","loss/train_loss 1.9911394119262695 220\n","loss/train_loss 1.7091500759124756 230\n","loss/train_loss 1.5872602462768555 240\n","loss/train_loss 1.7136591672897339 250\n","loss/train_loss 1.6810505390167236 260\n","loss/train_loss 1.9272451400756836 270\n","loss/train_loss 1.9805841445922852 280\n","loss/train_loss 2.312363624572754 290\n","loss/train_loss 1.803486943244934 300\n","loss/train_loss 1.7607156038284302 310\n","loss/train_loss 2.0984158515930176 320\n","loss/train_loss 1.7425014972686768 330\n","loss/train_loss 1.7537271976470947 340\n","loss/train_loss 1.865473747253418 350\n","loss/train_loss 1.7847381830215454 360\n","loss/train_loss 1.517561912536621 370\n","validation\n","50\n","100\n","150\n","200\n","250\n","loss/val_loss 1.0212028198242187 371\n","Overall Acc: \t 0.9167559881118166\n","val_metrics/Overall Acc: \t 0.9167559881118166 371\n","Mean Acc : \t 0.6150810082059842\n","val_metrics/Mean Acc : \t 0.6150810082059842 371\n","FreqW Acc : \t 0.856805699991154\n","val_metrics/FreqW Acc : \t 0.856805699991154 371\n","Mean IoU : \t 0.5130947399435687\n","val_metrics/Mean IoU : \t 0.5130947399435687 371\n","val_metrics/cls_0 0.9556316181311933 371\n","val_metrics/cls_1 0.6897828649509242 371\n","val_metrics/cls_2 0.8615980121610075 371\n","val_metrics/cls_3 0.2175914597315955 371\n","val_metrics/cls_4 0.34378950128974634 371\n","val_metrics/cls_5 0.431973033109957 371\n","val_metrics/cls_6 0.3780150443902561 371\n","val_metrics/cls_7 0.5175758906389026 371\n","val_metrics/cls_8 0.8692864262425557 371\n","val_metrics/cls_9 0.3883391383194449 371\n","val_metrics/cls_10 0.8954741467154919 371\n","val_metrics/cls_11 0.6248324364728493 371\n","val_metrics/cls_12 0.2295948698413158 371\n","val_metrics/cls_13 0.8719817762124716 371\n","val_metrics/cls_14 0.08012566298586653 371\n","val_metrics/cls_15 0.48159247951630296 371\n","val_metrics/cls_16 0.1490710787905119 371\n","val_metrics/cls_17 0.17480465319755653 371\n","val_metrics/cls_18 0.5877399662298559 371\n","loss/train_loss 1.9770277738571167 10\n","loss/train_loss 1.7198338508605957 20\n","loss/train_loss 1.9295108318328857 30\n","loss/train_loss 1.766787052154541 40\n","loss/train_loss 1.7058384418487549 50\n","loss/train_loss 2.1881422996520996 60\n","loss/train_loss 1.908290982246399 70\n","loss/train_loss 1.802693486213684 80\n","loss/train_loss 1.9136956930160522 90\n","loss/train_loss 1.8925186395645142 100\n","loss/train_loss 2.152174711227417 110\n","loss/train_loss 1.774489402770996 120\n","loss/train_loss 1.8571152687072754 130\n","loss/train_loss 1.8415849208831787 140\n","loss/train_loss 2.0066895484924316 150\n","loss/train_loss 1.7201354503631592 160\n","loss/train_loss 2.0939674377441406 170\n","loss/train_loss 1.859095573425293 180\n","loss/train_loss 1.7611136436462402 190\n","loss/train_loss 1.8590787649154663 200\n","loss/train_loss 1.8925166130065918 210\n","loss/train_loss 2.22690749168396 220\n","loss/train_loss 1.6982985734939575 230\n","loss/train_loss 1.6211233139038086 240\n","loss/train_loss 1.7039464712142944 250\n","loss/train_loss 1.9248119592666626 260\n","loss/train_loss 1.8772927522659302 270\n","loss/train_loss 1.9074093103408813 280\n","loss/train_loss 2.0239083766937256 290\n","loss/train_loss 2.1403322219848633 300\n","loss/train_loss 1.741004467010498 310\n","loss/train_loss 2.32747745513916 320\n","loss/train_loss 1.8733112812042236 330\n","loss/train_loss 1.8496012687683105 340\n","loss/train_loss 1.8233081102371216 350\n","loss/train_loss 1.8911232948303223 360\n","loss/train_loss 1.7356890439987183 370\n","validation\n","50\n","100\n","150\n","200\n","250\n","loss/val_loss 1.188347839832306 371\n","Overall Acc: \t 0.8721943914917074\n","val_metrics/Overall Acc: \t 0.8721943914917074 371\n","Mean Acc : \t 0.5777037186694296\n","val_metrics/Mean Acc : \t 0.5777037186694296 371\n","FreqW Acc : \t 0.7979063759457499\n","val_metrics/FreqW Acc : \t 0.7979063759457499 371\n","Mean IoU : \t 0.4409039212572826\n","val_metrics/Mean IoU : \t 0.4409039212572826 371\n","val_metrics/cls_0 0.9301080259374279 371\n","val_metrics/cls_1 0.5482952734682277 371\n","val_metrics/cls_2 0.7583786562342344 371\n","val_metrics/cls_3 0.06967255413377212 371\n","val_metrics/cls_4 0.22450229548637265 371\n","val_metrics/cls_5 0.3618530817129305 371\n","val_metrics/cls_6 0.24487867898978694 371\n","val_metrics/cls_7 0.5103932240189551 371\n","val_metrics/cls_8 0.8281720952433516 371\n","val_metrics/cls_9 0.4241212577843395 371\n","val_metrics/cls_10 0.8686274958115608 371\n","val_metrics/cls_11 0.5778501290944996 371\n","val_metrics/cls_12 0.24262034349378253 371\n","val_metrics/cls_13 0.7767134596353493 371\n","val_metrics/cls_14 0.06599214252673859 371\n","val_metrics/cls_15 0.31266215512003925 371\n","val_metrics/cls_16 0.044763551323355806 371\n","val_metrics/cls_17 0.02166049379482317 371\n","val_metrics/cls_18 0.5659095900788214 371\n","loss/train_loss 2.0986552238464355 10\n","loss/train_loss 1.6887654066085815 20\n","loss/train_loss 1.8980028629302979 30\n","loss/train_loss 1.93113374710083 40\n","loss/train_loss 1.8009028434753418 50\n","loss/train_loss 1.8942606449127197 60\n","loss/train_loss 2.0413918495178223 70\n","loss/train_loss 1.6619371175765991 80\n","loss/train_loss 1.6783987283706665 90\n","loss/train_loss 1.8417260646820068 100\n","loss/train_loss 1.493741512298584 110\n","loss/train_loss 1.6907672882080078 120\n","loss/train_loss 1.640429973602295 130\n","loss/train_loss 1.6289509534835815 140\n","loss/train_loss 1.7714877128601074 150\n","loss/train_loss 1.84658682346344 160\n","loss/train_loss 2.0012009143829346 170\n","loss/train_loss 1.894450068473816 180\n","loss/train_loss 1.7093093395233154 190\n","loss/train_loss 1.8940098285675049 200\n","loss/train_loss 1.7758839130401611 210\n","loss/train_loss 1.853060245513916 220\n","loss/train_loss 1.5907504558563232 230\n","loss/train_loss 1.7972533702850342 240\n","loss/train_loss 2.1076738834381104 250\n","loss/train_loss 1.749194622039795 260\n","loss/train_loss 1.6105446815490723 270\n","loss/train_loss 1.8316454887390137 280\n","loss/train_loss 1.9269967079162598 290\n","loss/train_loss 2.046257495880127 300\n","loss/train_loss 1.9513559341430664 310\n","loss/train_loss 1.6616184711456299 320\n","loss/train_loss 1.7759934663772583 330\n","loss/train_loss 1.8709502220153809 340\n","loss/train_loss 1.9222321510314941 350\n","loss/train_loss 1.7331675291061401 360\n","loss/train_loss 1.7846124172210693 370\n","validation\n","50\n","100\n","150\n","200\n","250\n","loss/val_loss 1.13450732421875 371\n","Overall Acc: \t 0.9106508603884866\n","val_metrics/Overall Acc: \t 0.9106508603884866 371\n","Mean Acc : \t 0.5857396389087051\n","val_metrics/Mean Acc : \t 0.5857396389087051 371\n","FreqW Acc : \t 0.8498587236019424\n","val_metrics/FreqW Acc : \t 0.8498587236019424 371\n","Mean IoU : \t 0.4765902449587383\n","val_metrics/Mean IoU : \t 0.4765902449587383 371\n","val_metrics/cls_0 0.9591407342531167 371\n","val_metrics/cls_1 0.6995270672452917 371\n","val_metrics/cls_2 0.837878626465867 371\n","val_metrics/cls_3 0.15829819211049165 371\n","val_metrics/cls_4 0.309219807261773 371\n","val_metrics/cls_5 0.4156845518566981 371\n","val_metrics/cls_6 0.3150744411981563 371\n","val_metrics/cls_7 0.4508512550740478 371\n","val_metrics/cls_8 0.8666838310982473 371\n","val_metrics/cls_9 0.41442171689824236 371\n","val_metrics/cls_10 0.9168995355103632 371\n","val_metrics/cls_11 0.608369240135952 371\n","val_metrics/cls_12 0.2832280824083392 371\n","val_metrics/cls_13 0.8588190952517301 371\n","val_metrics/cls_14 0.028831673337767063 371\n","val_metrics/cls_15 0.1426928219214198 371\n","val_metrics/cls_16 0.1113823219981408 371\n","val_metrics/cls_17 0.09323236363683743 371\n","val_metrics/cls_18 0.5849792965535469 371\n","loss/train_loss 2.2315728664398193 10\n","loss/train_loss 1.7030200958251953 20\n","loss/train_loss 2.930798292160034 30\n","loss/train_loss 1.7655987739562988 40\n","loss/train_loss 1.817345380783081 50\n","loss/train_loss 1.924203634262085 60\n","loss/train_loss 1.8421826362609863 70\n","loss/train_loss 1.6757928133010864 80\n","loss/train_loss 2.1856021881103516 90\n","loss/train_loss 1.591512680053711 100\n","loss/train_loss 1.7703139781951904 110\n","loss/train_loss 1.837393045425415 120\n","loss/train_loss 1.653156042098999 130\n","loss/train_loss 1.646100401878357 140\n","loss/train_loss 2.0322394371032715 150\n","loss/train_loss 1.6635785102844238 160\n","loss/train_loss 2.052196502685547 170\n","loss/train_loss 2.0749435424804688 180\n","loss/train_loss 1.781978726387024 190\n","loss/train_loss 1.9182934761047363 200\n","loss/train_loss 1.7454115152359009 210\n","loss/train_loss 1.7508665323257446 220\n","loss/train_loss 1.7837028503417969 230\n","loss/train_loss 1.665809988975525 240\n","loss/train_loss 1.8841025829315186 250\n","loss/train_loss 1.8357266187667847 260\n","loss/train_loss 1.731870174407959 270\n","loss/train_loss 1.859249472618103 280\n","loss/train_loss 1.9213123321533203 290\n","loss/train_loss 2.1309638023376465 300\n","loss/train_loss 1.9049845933914185 310\n","loss/train_loss 1.9790208339691162 320\n","loss/train_loss 1.856017827987671 330\n","loss/train_loss 1.9227956533432007 340\n","loss/train_loss 1.9618020057678223 350\n","loss/train_loss 1.8040131330490112 360\n","loss/train_loss 1.8193888664245605 370\n","validation\n","50\n","100\n","150\n","200\n","250\n","loss/val_loss 1.1292373416423798 371\n","Overall Acc: \t 0.9103332441097597\n","val_metrics/Overall Acc: \t 0.9103332441097597 371\n","Mean Acc : \t 0.5923565820908496\n","val_metrics/Mean Acc : \t 0.5923565820908496 371\n","FreqW Acc : \t 0.8511306844124112\n","val_metrics/FreqW Acc : \t 0.8511306844124112 371\n","Mean IoU : \t 0.4758186383498336\n","val_metrics/Mean IoU : \t 0.4758186383498336 371\n","val_metrics/cls_0 0.9581099443143146 371\n","val_metrics/cls_1 0.7039949213051225 371\n","val_metrics/cls_2 0.8434688480117618 371\n","val_metrics/cls_3 0.07542694701973983 371\n","val_metrics/cls_4 0.2703807763094424 371\n","val_metrics/cls_5 0.44700112536853687 371\n","val_metrics/cls_6 0.3948751811177474 371\n","val_metrics/cls_7 0.49039738455927867 371\n","val_metrics/cls_8 0.87211150522797 371\n","val_metrics/cls_9 0.46411723252279263 371\n","val_metrics/cls_10 0.8980510741239204 371\n","val_metrics/cls_11 0.5690404043967489 371\n","val_metrics/cls_12 0.14962674821771277 371\n","val_metrics/cls_13 0.8651766900792185 371\n","val_metrics/cls_14 0.02767851299405448 371\n","val_metrics/cls_15 0.19344335221309272 371\n","val_metrics/cls_16 0.12356346165024361 371\n","val_metrics/cls_17 0.16012885278841416 371\n","val_metrics/cls_18 0.5339611664267272 371\n","loss/train_loss 1.8033949136734009 10\n","loss/train_loss 1.7316089868545532 20\n","loss/train_loss 1.7675179243087769 30\n","loss/train_loss 2.0058560371398926 40\n","loss/train_loss 1.7914884090423584 50\n","loss/train_loss 1.998439073562622 60\n","loss/train_loss 1.8685486316680908 70\n","loss/train_loss 1.6763843297958374 80\n","loss/train_loss 2.0221028327941895 90\n","loss/train_loss 1.663865327835083 100\n","loss/train_loss 1.8506560325622559 110\n","loss/train_loss 1.7368313074111938 120\n","loss/train_loss 1.741405725479126 130\n","loss/train_loss 1.691216230392456 140\n","loss/train_loss 2.0826945304870605 150\n","loss/train_loss 1.719757318496704 160\n","loss/train_loss 1.9205759763717651 170\n","loss/train_loss 2.444551944732666 180\n","loss/train_loss 2.3796141147613525 190\n","loss/train_loss 1.8278981447219849 200\n","loss/train_loss 1.6948381662368774 210\n","loss/train_loss 1.867903232574463 220\n","loss/train_loss 1.7262177467346191 230\n","loss/train_loss 1.5598182678222656 240\n","loss/train_loss 1.9732775688171387 250\n","loss/train_loss 1.7037105560302734 260\n","loss/train_loss 1.6308231353759766 270\n","loss/train_loss 2.0751760005950928 280\n","loss/train_loss 1.9971199035644531 290\n","loss/train_loss 1.8613158464431763 300\n","loss/train_loss 1.789682388305664 310\n","loss/train_loss 2.1970772743225098 320\n","loss/train_loss 2.303109645843506 330\n","loss/train_loss 1.8991466760635376 340\n","loss/train_loss 1.9520182609558105 350\n","loss/train_loss 1.7862884998321533 360\n","loss/train_loss 1.7822107076644897 370\n","validation\n","50\n","100\n","150\n","200\n","250\n","loss/val_loss 1.0835177586078644 371\n","Overall Acc: \t 0.9158790265132811\n","val_metrics/Overall Acc: \t 0.9158790265132811 371\n","Mean Acc : \t 0.5927551454132843\n","val_metrics/Mean Acc : \t 0.5927551454132843 371\n","FreqW Acc : \t 0.8562352395002093\n","val_metrics/FreqW Acc : \t 0.8562352395002093 371\n","Mean IoU : \t 0.4979671063314652\n","val_metrics/Mean IoU : \t 0.4979671063314652 371\n","val_metrics/cls_0 0.9590267490227132 371\n","val_metrics/cls_1 0.7057268145903556 371\n","val_metrics/cls_2 0.8474425945260228 371\n","val_metrics/cls_3 0.2628134250328334 371\n","val_metrics/cls_4 0.30332447749239083 371\n","val_metrics/cls_5 0.39888500409918193 371\n","val_metrics/cls_6 0.22110753147496207 371\n","val_metrics/cls_7 0.54399045403889 371\n","val_metrics/cls_8 0.8797636062890336 371\n","val_metrics/cls_9 0.45116618740773684 371\n","val_metrics/cls_10 0.9017290955945219 371\n","val_metrics/cls_11 0.6259832402383871 371\n","val_metrics/cls_12 0.1408172293657378 371\n","val_metrics/cls_13 0.8558615626337742 371\n","val_metrics/cls_14 0.08356803567691028 371\n","val_metrics/cls_15 0.407071294639278 371\n","val_metrics/cls_16 0.25513551554646763 371\n","val_metrics/cls_17 0.035005823723218324 371\n","val_metrics/cls_18 0.5829563789054232 371\n","loss/train_loss 1.7922687530517578 10\n","loss/train_loss 1.6426596641540527 20\n","loss/train_loss 1.7946680784225464 30\n","loss/train_loss 1.737088680267334 40\n","loss/train_loss 1.9889030456542969 50\n","loss/train_loss 2.3126015663146973 60\n","loss/train_loss 1.8820884227752686 70\n","loss/train_loss 1.8334189653396606 80\n","loss/train_loss 1.8714054822921753 90\n","loss/train_loss 1.6600067615509033 100\n","loss/train_loss 1.676776647567749 110\n","loss/train_loss 2.1146366596221924 120\n","loss/train_loss 1.7390269041061401 130\n","loss/train_loss 1.6516767740249634 140\n","loss/train_loss 1.969414472579956 150\n","loss/train_loss 1.8203924894332886 160\n","loss/train_loss 2.070556640625 170\n","loss/train_loss 1.9119555950164795 180\n","loss/train_loss 1.9731645584106445 190\n","loss/train_loss 1.9201185703277588 200\n","loss/train_loss 1.737502098083496 210\n","loss/train_loss 1.9319287538528442 220\n","loss/train_loss 1.7853161096572876 230\n","loss/train_loss 1.7002944946289062 240\n","loss/train_loss 1.7900769710540771 250\n","loss/train_loss 1.8602851629257202 260\n","loss/train_loss 1.7165770530700684 270\n","loss/train_loss 1.9645321369171143 280\n","loss/train_loss 1.8097467422485352 290\n","loss/train_loss 1.904526948928833 300\n","loss/train_loss 1.9071009159088135 310\n","loss/train_loss 2.1292293071746826 320\n","loss/train_loss 2.1617493629455566 330\n","loss/train_loss 1.7832943201065063 340\n","loss/train_loss 1.8994930982589722 350\n","loss/train_loss 1.9185041189193726 360\n","loss/train_loss 1.786886215209961 370\n","validation\n","50\n","100\n","150\n","200\n","250\n","loss/val_loss 1.0484869515895843 371\n","Overall Acc: \t 0.9105484949497021\n","val_metrics/Overall Acc: \t 0.9105484949497021 371\n","Mean Acc : \t 0.5593451317033323\n","val_metrics/Mean Acc : \t 0.5593451317033323 371\n","FreqW Acc : \t 0.8451891014202024\n","val_metrics/FreqW Acc : \t 0.8451891014202024 371\n","Mean IoU : \t 0.47392531293661966\n","val_metrics/Mean IoU : \t 0.47392531293661966 371\n","val_metrics/cls_0 0.9533112334244571 371\n","val_metrics/cls_1 0.6913449634066475 371\n","val_metrics/cls_2 0.8481529339381013 371\n","val_metrics/cls_3 0.08082310173609136 371\n","val_metrics/cls_4 0.3194437142618576 371\n","val_metrics/cls_5 0.42285967581287404 371\n","val_metrics/cls_6 0.32974187538218824 371\n","val_metrics/cls_7 0.5007767550170003 371\n","val_metrics/cls_8 0.8620066301599344 371\n","val_metrics/cls_9 0.40909862517878987 371\n","val_metrics/cls_10 0.9086718759092258 371\n","val_metrics/cls_11 0.5555506535668574 371\n","val_metrics/cls_12 0.2653046854936225 371\n","val_metrics/cls_13 0.8197177774977952 371\n","val_metrics/cls_14 0.08219645293315143 371\n","val_metrics/cls_15 0.2494336954026308 371\n","val_metrics/cls_16 0.07624091627415525 371\n","val_metrics/cls_17 0.10256834792120201 371\n","val_metrics/cls_18 0.5273370324791898 371\n","loss/train_loss 1.7260208129882812 10\n","loss/train_loss 1.571225643157959 20\n","loss/train_loss 2.0291125774383545 30\n","loss/train_loss 1.783684492111206 40\n","loss/train_loss 1.733971357345581 50\n","loss/train_loss 1.9124870300292969 60\n","loss/train_loss 2.089341163635254 70\n","loss/train_loss 1.801729440689087 80\n","loss/train_loss 1.568885087966919 90\n","loss/train_loss 1.7660350799560547 100\n","loss/train_loss 1.8432767391204834 110\n","loss/train_loss 1.9490329027175903 120\n","loss/train_loss 1.6679294109344482 130\n","loss/train_loss 1.6053801774978638 140\n","loss/train_loss 1.9011101722717285 150\n","loss/train_loss 1.508744478225708 160\n","loss/train_loss 1.815556287765503 170\n","loss/train_loss 2.1038551330566406 180\n","loss/train_loss 1.7545419931411743 190\n","loss/train_loss 1.916115164756775 200\n","loss/train_loss 1.7818903923034668 210\n","loss/train_loss 1.9494125843048096 220\n","loss/train_loss 1.9102808237075806 230\n","loss/train_loss 1.7484726905822754 240\n","loss/train_loss 1.9258626699447632 250\n","loss/train_loss 1.891256332397461 260\n","loss/train_loss 1.7754268646240234 270\n","loss/train_loss 1.7859611511230469 280\n","loss/train_loss 1.9164848327636719 290\n","loss/train_loss 1.8475234508514404 300\n","loss/train_loss 1.8473334312438965 310\n","loss/train_loss 1.7844401597976685 320\n","loss/train_loss 2.0117554664611816 330\n","loss/train_loss 1.7599947452545166 340\n","loss/train_loss 1.9603757858276367 350\n","loss/train_loss 1.87436842918396 360\n","loss/train_loss 1.5802326202392578 370\n","validation\n","50\n","100\n","150\n","200\n","250\n","loss/val_loss 1.069938514471054 371\n","Overall Acc: \t 0.90872686319414\n","val_metrics/Overall Acc: \t 0.90872686319414 371\n","Mean Acc : \t 0.6018492771646757\n","val_metrics/Mean Acc : \t 0.6018492771646757 371\n","FreqW Acc : \t 0.8462665120609675\n","val_metrics/FreqW Acc : \t 0.8462665120609675 371\n","Mean IoU : \t 0.48939284355790313\n","val_metrics/Mean IoU : \t 0.48939284355790313 371\n","val_metrics/cls_0 0.9512257855267359 371\n","val_metrics/cls_1 0.6939372248072994 371\n","val_metrics/cls_2 0.837232710918145 371\n","val_metrics/cls_3 0.06571607180742739 371\n","val_metrics/cls_4 0.2559788303914021 371\n","val_metrics/cls_5 0.40105016383915165 371\n","val_metrics/cls_6 0.3604892005957691 371\n","val_metrics/cls_7 0.533543835893273 371\n","val_metrics/cls_8 0.8711154623111025 371\n","val_metrics/cls_9 0.45881672014396563 371\n","val_metrics/cls_10 0.9085574828131443 371\n","val_metrics/cls_11 0.615754365945795 371\n","val_metrics/cls_12 0.25252845345002833 371\n","val_metrics/cls_13 0.841037736378266 371\n","val_metrics/cls_14 0.0895021204108046 371\n","val_metrics/cls_15 0.32307507618820963 371\n","val_metrics/cls_16 0.18214996770769507 371\n","val_metrics/cls_17 0.09576905673878272 371\n","val_metrics/cls_18 0.5609837617331627 371\n","loss/train_loss 1.8824026584625244 10\n","loss/train_loss 1.8251622915267944 20\n","loss/train_loss 1.7619003057479858 30\n","loss/train_loss 2.0355772972106934 40\n","loss/train_loss 1.7498559951782227 50\n","loss/train_loss 1.964114785194397 60\n","loss/train_loss 1.9865779876708984 70\n","loss/train_loss 1.6842455863952637 80\n","loss/train_loss 1.8221924304962158 90\n","loss/train_loss 1.6799404621124268 100\n","loss/train_loss 1.6751744747161865 110\n","loss/train_loss 1.9358793497085571 120\n","loss/train_loss 1.811774492263794 130\n","loss/train_loss 1.622471570968628 140\n","loss/train_loss 2.132148027420044 150\n","loss/train_loss 1.7079451084136963 160\n","loss/train_loss 1.7831926345825195 170\n","loss/train_loss 2.434209108352661 180\n","loss/train_loss 1.769782304763794 190\n","loss/train_loss 1.7309788465499878 200\n","loss/train_loss 1.7346595525741577 210\n","loss/train_loss 1.8632683753967285 220\n","loss/train_loss 1.6692962646484375 230\n","loss/train_loss 1.7322964668273926 240\n","loss/train_loss 1.8092448711395264 250\n","loss/train_loss 2.093503952026367 260\n","loss/train_loss 1.5956742763519287 270\n","loss/train_loss 1.8977727890014648 280\n","loss/train_loss 1.976067066192627 290\n","loss/train_loss 1.9139134883880615 300\n","loss/train_loss 1.9119033813476562 310\n","loss/train_loss 2.0570058822631836 320\n","loss/train_loss 1.975642204284668 330\n","loss/train_loss 1.9533318281173706 340\n","loss/train_loss 2.0134835243225098 350\n","loss/train_loss 1.7727713584899902 360\n","loss/train_loss 1.6489347219467163 370\n","validation\n","50\n","100\n","150\n","200\n","250\n","loss/val_loss 1.1251007387638092 371\n","Overall Acc: \t 0.9036050776943495\n","val_metrics/Overall Acc: \t 0.9036050776943495 371\n","Mean Acc : \t 0.5799933860133666\n","val_metrics/Mean Acc : \t 0.5799933860133666 371\n","FreqW Acc : \t 0.8369526800085164\n","val_metrics/FreqW Acc : \t 0.8369526800085164 371\n","Mean IoU : \t 0.47218766128860407\n","val_metrics/Mean IoU : \t 0.47218766128860407 371\n","val_metrics/cls_0 0.9580228561274969 371\n","val_metrics/cls_1 0.7095578187423677 371\n","val_metrics/cls_2 0.8147466345426406 371\n","val_metrics/cls_3 0.18012251992383302 371\n","val_metrics/cls_4 0.3099117821343189 371\n","val_metrics/cls_5 0.33861805801513556 371\n","val_metrics/cls_6 0.2542745204262285 371\n","val_metrics/cls_7 0.5037350350828759 371\n","val_metrics/cls_8 0.8269514968738607 371\n","val_metrics/cls_9 0.4500408921986374 371\n","val_metrics/cls_10 0.8965356335981217 371\n","val_metrics/cls_11 0.6355504682326871 371\n","val_metrics/cls_12 0.19734436347504744 371\n","val_metrics/cls_13 0.8544391275605511 371\n","val_metrics/cls_14 0.06857504261028352 371\n","val_metrics/cls_15 0.1229714836679975 371\n","val_metrics/cls_16 0.14902321865131915 371\n","val_metrics/cls_17 0.10508561095473491 371\n","val_metrics/cls_18 0.5960590016653393 371\n"]}],"source":["st = glob_st = time.time()\n","not_yet_run_in_session = False\n","for epoch_id in range(start_epoch, local_max_epoch):\n","    for images, labels in dl:\n","        it += 1\n","        start_ts = time.time()\n","        \n","        model.train()\n","\n","        images = images.to(device)\n","        labels = labels.to(device)\n","        labels = torch.squeeze(labels, 1)\n"," \n","        optim.zero_grad()\n","\n","        out_main, out_detail = model(images)\n"," \n","        loss_ffm = criteria_ffm(out_main, labels)\n","        \n","        boundery_bce, boundery_dice = boundary_loss_func(out_detail, labels)\n","\n","        boundery_bce_loss = boundery_bce\n","        boundery_dice_loss = boundery_dice\n","\n","        loss = loss_ffm + boundery_bce_loss + boundery_dice_loss\n","\n","        loss.backward()\n","        optim.step()\n","\n","        loss_avg.append(loss.item())\n","\n","        loss_boundery_bce.append(boundery_bce_loss.item())\n","        loss_boundery_dice.append(boundery_dice_loss.item())\n","\n","        if (it + 1) % print_interval == 0:\n","            loss_avg = sum(loss_avg) / len(loss_avg)\n","            lr = optim.lr\n","            ed = time.time()\n","            t_intv, glob_t_intv = ed - st, ed - glob_st\n","            eta = int((max_iter - it) * (glob_t_intv / it))\n","            eta = str(timedelta(seconds=eta))\n","\n","            loss_boundery_bce_avg = sum(loss_boundery_bce) / len(loss_boundery_bce)\n","            loss_boundery_dice_avg = sum(loss_boundery_dice) / len(loss_boundery_dice)\n","            msg = ', '.join([\n","                'epoch: {epoch}/{max_epoch}'\n","                'it: {it}/{max_it}',\n","                'lr: {lr:4f}',\n","                'loss: {loss:.4f}',\n","                'boundery_bce_loss: {boundery_bce_loss:.4f}',\n","                'boundery_dice_loss: {boundery_dice_loss:.4f}',\n","                'eta: {eta}',\n","                'time: {time:.4f}',\n","            ]).format(\n","                epoch = epoch_id,\n","                max_epoch = max_epoch,\n","                it = it+1,\n","                max_it = epoch_iteration,\n","                lr = lr,\n","                loss = loss_avg,\n","                boundery_bce_loss = loss_boundery_bce_avg,\n","                boundery_dice_loss = loss_boundery_dice_avg,\n","                time = t_intv,\n","                eta = eta\n","            )\n","            \n","            logger.info(msg)\n","            print(\"loss/train_loss\", loss.item(), it + 1)\n","            loss_avg = []\n","            loss_boundery_bce = []\n","            loss_boundery_dice = []\n","            st = ed\n","\n","        if ((it + 1) % val_interval == 0 and it + 10 < epoch_iteration) or (it + 1) % epoch_iteration == 0:\n","            print('validation')\n","            torch.cuda.empty_cache()\n","            model.eval()\n","            loss_all = 0\n","            loss_n = 0\n","            with torch.no_grad():\n","                for i_val, (images_val, labels_val) in enumerate(dlval):\n","                    if (i_val + 1) % 50 == 0:\n","                        print(i_val + 1)\n","\n","                    images_val = images_val.to(device)\n","                    labels_val = labels_val.to(device)\n","                    labels_val = torch.squeeze(labels_val, 1)\n","\n","                    outputs = model(images_val)[0]\n","                    val_loss = criteria_val(outputs, labels_val)\n","\n","                    pred = outputs.data.max(1)[1].cpu().numpy()\n","                    gt = labels_val.data.cpu().numpy()\n","\n","                    running_metrics_val.update(gt, pred)\n","                    val_loss_meter.update(val_loss.item())\n","\n","            print(\"loss/val_loss\", val_loss_meter.avg, it + 1)\n","            logger.info(\"Epoch %3d Iter %d Val Loss: %.4f\" % (epoch_id, it + 1, val_loss_meter.avg))\n","\n","            score, class_iou = running_metrics_val.get_scores()\n","            for k, v in score.items():\n","                print(k, v)\n","                logger.info(\"{}: {}\".format(k, v))\n","                print(\"val_metrics/{}\".format(k), v, it+ 1)\n","\n","            for k, v in class_iou.items():\n","                logger.info(\"{}: {}\".format(k, v))\n","                print(\"val_metrics/cls_{}\".format(k), v, it+ 1)\n","\n","            val_loss_meter.reset()\n","            running_metrics_val.reset()\n","\n","            state = {\n","                    \"epoch\": epoch_id,\n","                    \"iteration\": it+ 1,\n","                    \"model_state\": model.state_dict(),\n","                    \"optimizer_state\": optim.get_state(),\n","            }\n","            save_path = os.path.join(\n","                writer.file_writer.get_logdir(),\n","                \"{}_{}_checkpoint.pkl\".format(model_arch, cfg_data['dataset']),\n","            )\n","            torch.save(state, save_path)\n","\n","            if score[\"Mean IoU : \\t\"] >= best_iou:\n","                best_iou = score[\"Mean IoU : \\t\"]\n","                state = {\n","                    \"epoch\": epoch_id,\n","                    \"iteration\":it+ 1,\n","                    \"model_state\": model.state_dict(),\n","                    \"best_iou\": best_iou,\n","                }\n","                save_path = os.path.join(\n","                    writer.file_writer.get_logdir(),\n","                    \"{}_{}_best_model.pkl\".format(model_arch, cfg_data['dataset']),\n","                )\n","                torch.save(state, save_path)\n","            torch.cuda.empty_cache()\n","    it = 0"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RH8UeQwnQlgY"},"outputs":[],"source":["# with torch.no_grad():\n","#     for (images_val, labels_val, _) in valloader:\n","#         images_val = images_val.to(device)\n","#         labels_val = labels_val.to(device)\n","\n","#         outputs = model(images_val)\n","#         outputs = output_val_upsample(outputs)\n","#         val_loss = loss_fn(input=outputs, target=labels_val)\n","\n","#         pred = outputs.data.max(1)[1].cpu().numpy()\n","#         gt = labels_val.data.cpu().numpy()\n","\n","#         running_metrics_val.update(gt, pred)\n","#         val_loss_meter.update(val_loss.item())\n","\n","# writer.add_scalar(\"loss/val_loss\", val_loss_meter.avg, i + 1)\n","# logger.info(\"Iter %d Val Loss: %.4f\" % (i + 1, val_loss_meter.avg))\n","\n","# score, class_iou = running_metrics_val.get_scores()"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"STDC_dilated_3831.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}