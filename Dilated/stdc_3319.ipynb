{"cells":[{"cell_type":"markdown","metadata":{"id":"Oc4QzK2lMdkH"},"source":["# STDC with dilations"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":15754,"status":"ok","timestamp":1648018507468,"user":{"displayName":"Maxim Dobrokhvalov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GivhSqWinIWPCnla4i9mS0iTldWMUfolXP7x1EL=s64","userId":"05960264113093771023"},"user_tz":-180},"id":"IrFsKEKW7429","outputId":"5d42066e-1d25-47bc-8065-8a5b7e165ffc"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting tensorboardX\n","  Downloading tensorboardX-2.5-py2.py3-none-any.whl (125 kB)\n","\u001b[?25l\r\u001b[K     |██▋                             | 10 kB 15.6 MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 20 kB 8.7 MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 30 kB 5.5 MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 40 kB 5.0 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 51 kB 3.9 MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 61 kB 4.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 71 kB 4.7 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 81 kB 4.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▌        | 92 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 102 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 112 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 122 kB 5.2 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 125 kB 5.2 MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from tensorboardX) (1.21.5)\n","Requirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.7/dist-packages (from tensorboardX) (3.17.3)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from tensorboardX) (1.15.0)\n","Installing collected packages: tensorboardX\n","Successfully installed tensorboardX-2.5\n"]}],"source":["import sys\n","sys.path.insert(0, '.')\n","import os\n","import logging\n","import random\n","import time\n","import math\n","import torch\n","import numpy as np \n","import torch.nn as nn\n","import torch.nn.functional as F\n","\n","from torch.nn import init\n","from torch.utils import data\n","from datetime import datetime, timedelta\n","from collections import OrderedDict\n","\n","from torchsummary import summary\n","\n","import torch.distributed as dist\n","\n"," \n","!pip install tensorboardX\n","from tensorboardX import SummaryWriter"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZvH1JPHzSxXK"},"outputs":[],"source":["os.environ['CUDA_LAUNCH_BLOCKING'] = '1'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_yTqA_v7SK42"},"outputs":[],"source":["batch_size = 8\n","n_workers = 2\n","print_interval=10\n","val_interval=500\n","\n","n_classes = 19\n","\n","model_arch = 'STDC_dilated'\n","\n","\n","bn_mom = 0.1\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BdAvR6h_Y43C"},"outputs":[],"source":["# Setup device\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"]},{"cell_type":"markdown","metadata":{"id":"_rlqCnjINmRs"},"source":["---\n","## Architecture"]},{"cell_type":"markdown","metadata":{"id":"ej7GwMiBroOM"},"source":["### Blocks"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"IfQMxl1EysQu"},"outputs":[],"source":["class DilatedConv(nn.Module):\n","    def __init__(self, in_planes, out_planes, kernel_size=3, dilation=1, stride=1, bias=False):\n","        super().__init__()\n","        num_splits = 2\n","        # print(\"1\", out_planes, num_splits)\n","        assert(out_planes%num_splits == 0)\n","        conv_in_planes = in_planes // num_splits\n","        conv_out_planes = out_planes // num_splits\n","        # print(\"2\", conv_out_planes, group_width)\n","        # assert(conv_out_planes%group_width == 0)\n","        # ------------------\n","        # TODO: change groups count\n","        # groups = conv_out_planes // group_width\n","        groups = 2\n","        conv_1 = nn.Conv2d(conv_in_planes, conv_out_planes, kernel_size, padding=kernel_size//2, dilation=1, stride=stride, groups=groups, bias=bias)\n","        conv_n = nn.Conv2d(conv_in_planes, conv_out_planes, 3, padding=dilation, dilation=dilation, stride=stride, groups=groups, bias=bias)\n","        self.convs=nn.ModuleList([conv_1, conv_n])\n","        self.num_splits=num_splits\n","        self.init_weight()\n","    \n","    def forward(self,x):\n","        x=torch.tensor_split(x,self.num_splits,dim=1)\n","        res = []\n","        for i in range(self.num_splits):\n","            res.append(self.convs[i](x[i]))\n","        return torch.cat(res,dim=1)\n","    \n","    def init_weight(self):\n","        for ly in self.children():\n","            if isinstance(ly, nn.Conv2d):\n","                nn.init.kaiming_normal_(ly.weight, a=1)\n","                if not ly.bias is None: nn.init.constant_(ly.bias, 0)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"VehqKGzJyoV9"},"outputs":[],"source":["class ConvX(nn.Module):\n","    def __init__(self, in_planes, out_planes, kernel=3, stride=1, dilation=1):\n","        super(ConvX, self).__init__()\n","        \n","        if dilation == 1:\n","            self.conv = nn.Conv2d(in_planes, out_planes, kernel_size=kernel, stride=stride, padding=kernel//2, bias=False)\n","        else:\n","            self.conv = DilatedConv(in_planes, out_planes, kernel_size=kernel, stride=stride, dilation=dilation, bias=False)\n","        self.bn = nn.BatchNorm2d(out_planes)\n","        self.relu = nn.ReLU(inplace=True)\n","        self.init_weight()\n","\n","    def forward(self, x):\n","        out = self.relu(self.bn(self.conv(x)))\n","        return out\n","\n","    def init_weight(self):\n","        for ly in self.children():\n","            if isinstance(ly, nn.Conv2d):\n","                nn.init.kaiming_normal_(ly.weight, a=1)\n","                if not ly.bias is None: nn.init.constant_(ly.bias, 0)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gwHZ02vWozj0"},"outputs":[],"source":["class CatBottleneck(nn.Module):\n","    def __init__(self, in_planes, out_planes, block_num=4, stride=1, dilation=1):\n","        super(CatBottleneck, self).__init__()\n","        assert block_num > 1, print(\"block number should be larger than 1.\")\n","        self.conv_list = nn.ModuleList()\n","        self.stride = stride\n","        if stride == 2:\n","            self.avd_layer = nn.Sequential(\n","                nn.Conv2d(out_planes//2, out_planes//2, kernel_size=3, stride=2, padding=1, groups=out_planes//2, bias=False),\n","                nn.BatchNorm2d(out_planes//2),\n","            )\n","            self.skip = nn.AvgPool2d(kernel_size=3, stride=2, padding=1)\n","            stride = 1\n","\n","        for idx in range(block_num):\n","            blk = None\n","            if idx == 0:\n","                blk = ConvX(in_planes, out_planes//2, kernel=1)\n","            elif idx == 1 and block_num == 2:\n","                blk = ConvX(out_planes//2, out_planes//2, stride=stride, dilation=dilation)\n","            elif idx == 1 and block_num > 2:\n","                blk = ConvX(out_planes//2, out_planes//4, stride=stride, dilation=dilation)\n","            elif idx < block_num - 1:\n","                blk = ConvX(out_planes//int(math.pow(2, idx)), out_planes//int(math.pow(2, idx+1)), dilation=dilation)\n","            else:\n","                blk = ConvX(out_planes//int(math.pow(2, idx)), out_planes//int(math.pow(2, idx)), dilation=dilation)\n","            self.conv_list.append(blk)\n","            \n","    def forward(self, x):\n","        out_list = []\n","        out1 = self.conv_list[0](x)\n","\n","        for idx, conv in enumerate(self.conv_list[1:]):\n","            if idx == 0:\n","                if self.stride == 2:\n","                    out = conv(self.avd_layer(out1))\n","                else:\n","                    out = conv(out1)\n","            else:\n","                out = conv(out)\n","            out_list.append(out)\n","\n","        if self.stride == 2:\n","            out1 = self.skip(out1)\n","        out_list.insert(0, out1)\n","\n","        out = torch.cat(out_list, dim=1)\n","        return out"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OIqdvmi-yzg4"},"outputs":[],"source":["class BiSeNetOutput(nn.Module):\n","    def __init__(self, in_chan, mid_chan, n_classes, *args, **kwargs):\n","        super(BiSeNetOutput, self).__init__()\n","        self.conv = ConvX(in_chan, mid_chan, kernel=3, stride=1)\n","        self.conv_out = nn.Conv2d(mid_chan, n_classes, kernel_size=1, bias=False)\n","        self.init_weight()\n","\n","    def forward(self, x):\n","        x = self.conv(x)\n","        x = self.conv_out(x)\n","        return x\n","\n","    def init_weight(self):\n","        for ly in self.children():\n","            if isinstance(ly, nn.Conv2d):\n","                nn.init.kaiming_normal_(ly.weight, a=1)\n","                if not ly.bias is None: nn.init.constant_(ly.bias, 0)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NUHie9tesVSD"},"outputs":[],"source":["class Decoder(nn.Module):\n","    def __init__(self, num_classes, channels):\n","        super().__init__()\n","        channels4, channels8, channels16 = channels\n","        self.head16=ConvX(channels16, 128, 1)\n","        self.head8=ConvX(channels8, 128, 1)\n","        self.head4=ConvX(channels4, 8, 1)\n","        self.conv8=ConvX(128,64,3,1,1)\n","        self.conv4=ConvX(64+8,64,3,1,1)\n","        self.classifier=nn.Conv2d(64, num_classes, 1)\n","\n","    def forward(self, x):\n","        x4, x8, x16 = x\n","        x16=self.head16(x16)\n","        x8=self.head8(x8)\n","        x4=self.head4(x4)\n","        x16 = F.interpolate(x16, size=x8.shape[-2:], mode='bilinear', align_corners=False)\n","        x8= x8 + x16\n","        x8=self.conv8(x8)\n","        x8 = F.interpolate(x8, size=x4.shape[-2:], mode='bilinear', align_corners=False)\n","        x4=torch.cat((x8,x4),dim=1)\n","        x4=self.conv4(x4)\n","        x4=self.classifier(x4)\n","        return x4"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"88rzHfln70PP"},"outputs":[],"source":["class STDC_dilated(nn.Module):\n","    def __init__(self, blocks_dilation_and_stride = [], target_planes = 256, n_classes=19):\n","        super(STDC_dilated, self).__init__()\n","        self.conv0 = ConvX( 3, 32, kernel=3, stride=2)\n","        self.conv1 = ConvX(32, 64, kernel=3, stride=2)\n","        planes = 64\n","        blocks = []\n","        outs = []\n","        channels = []\n","        for i, block_info in enumerate(blocks_dilation_and_stride):\n","            dilation, stride = block_info\n","            in_planes = planes\n","            out_planes = planes\n","            if planes < target_planes:\n","                out_planes = min(out_planes * 2, target_planes)\n","                planes = out_planes\n","            \n","            blocks.append(CatBottleneck(in_planes, out_planes, dilation=dilation, stride=stride))\n","            if i == 0 or i ==len(blocks_dilation_and_stride)-1 or stride == 2:\n","                channels.append(out_planes)\n","                # outs.append(BiSeNetOutput(out_planes, 256, n_classes))\n","        self.blocks = nn.ModuleList(blocks)\n","        self.detail_out = BiSeNetOutput(channels[0], 64, 1)\n","        self.decoder = Decoder(19, channels[1:])\n","        # self.outs = nn.ModuleList(outs)\n","    \n","    def forward(self, x):\n","        out = self.conv0(x)\n","        out = self.conv1(out)\n","        store_out = []\n","        for i, module in enumerate(self.blocks):\n","            out = module(out)\n","            if i == 0 or i == len(self.blocks)-1 or module.stride == 2:\n","                # print(r.shape)\n","                # store_out.append(self.outs[len(store_out)](out))\n","                store_out.append(out)\n","        out_detail = self.detail_out(store_out[0])\n","        out = self.decoder(store_out[1:])\n","        out_detail = F.interpolate(out_detail, size=x.shape[-2:], mode='bilinear', align_corners=False)\n","        out = F.interpolate(out, size=x.shape[-2:], mode='bilinear', align_corners=False)\n","        return out, out_detail"]},{"cell_type":"markdown","metadata":{"id":"MfAtjams6ikd"},"source":["---\n","## Loss & Optimizer"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"x1X1GCpDNvej"},"outputs":[],"source":["class OhemCELoss(nn.Module):\n","    def __init__(self, thresh, n_min, ignore_lb=255, *args, **kwargs):\n","        super(OhemCELoss, self).__init__()\n","        self.thresh = -torch.log(torch.tensor(thresh, dtype=torch.float)).to(device)\n","        self.n_min = n_min\n","        self.ignore_lb = ignore_lb\n","        self.criteria = nn.CrossEntropyLoss(ignore_index=ignore_lb, reduction='none')\n","\n","    def forward(self, logits, labels):\n","        N, C, H, W = logits.size()\n","        loss = self.criteria(logits, labels).view(-1)\n","        loss, _ = torch.sort(loss, descending=True)\n","        if loss[self.n_min] > self.thresh:\n","            loss = loss[loss>self.thresh]\n","        else:\n","            loss = loss[:self.n_min]\n","        return torch.mean(loss)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3AtvMtbc_LfS"},"outputs":[],"source":["float_tensor_type = torch.cuda.FloatTensor if device.type=='cuda' else torch.FloatTensor"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Hxwvvyh6PdMg"},"outputs":[],"source":["def dice_loss_func(input, target):\n","    smooth = 1.\n","    n = input.size(0)\n","    iflat = input.view(n, -1)\n","    tflat = target.view(n, -1)\n","    intersection = (iflat * tflat).sum(1)\n","    loss = 1 - ((2. * intersection + smooth) /\n","                (iflat.sum(1) + tflat.sum(1) + smooth))\n","    return loss.mean()\n","\n","\n","class DetailAggregateLoss(nn.Module):\n","    def __init__(self, *args, **kwargs):\n","        super(DetailAggregateLoss, self).__init__()\n","        \n","        self.laplacian_kernel = torch.tensor(\n","            [-1, -1, -1, -1, 8, -1, -1, -1, -1],\n","            dtype=torch.float32).reshape(1, 1, 3, 3).requires_grad_(False).type(float_tensor_type)        \n","\n","        self.fuse_kernel = torch.nn.Parameter(torch.tensor([[6./10], [3./10], [1./10]],\n","            dtype=torch.float32).reshape(1, 3, 1, 1).type(float_tensor_type))\n","\n","    def forward(self, boundary_logits, gtmasks):\n","\n","        boundary_targets = F.conv2d(gtmasks.unsqueeze(1).type(float_tensor_type), self.laplacian_kernel, padding=1)\n","        boundary_targets = boundary_targets.clamp(min=0)\n","        boundary_targets[boundary_targets > 0.1] = 1\n","        boundary_targets[boundary_targets <= 0.1] = 0\n","\n","        boundary_targets_x2 = F.conv2d(gtmasks.unsqueeze(1).type(float_tensor_type), self.laplacian_kernel, stride=2, padding=1)\n","        boundary_targets_x2 = boundary_targets_x2.clamp(min=0)\n","        \n","        boundary_targets_x4 = F.conv2d(gtmasks.unsqueeze(1).type(float_tensor_type), self.laplacian_kernel, stride=4, padding=1)\n","        boundary_targets_x4 = boundary_targets_x4.clamp(min=0)\n","\n","        boundary_targets_x4_up = F.interpolate(boundary_targets_x4, boundary_targets.shape[2:], mode='nearest')\n","        boundary_targets_x2_up = F.interpolate(boundary_targets_x2, boundary_targets.shape[2:], mode='nearest')\n","        \n","        boundary_targets_x2_up[boundary_targets_x2_up > 0.1] = 1\n","        boundary_targets_x2_up[boundary_targets_x2_up <= 0.1] = 0\n","        \n","        \n","        boundary_targets_x4_up[boundary_targets_x4_up > 0.1] = 1\n","        boundary_targets_x4_up[boundary_targets_x4_up <= 0.1] = 0\n","       \n","        boudary_targets_pyramids = torch.stack((boundary_targets, boundary_targets_x2_up, boundary_targets_x4_up), dim=1)\n","        \n","        boudary_targets_pyramids = boudary_targets_pyramids.squeeze(2)\n","        boudary_targets_pyramid = F.conv2d(boudary_targets_pyramids, self.fuse_kernel)\n","\n","        boudary_targets_pyramid[boudary_targets_pyramid > 0.1] = 1\n","        boudary_targets_pyramid[boudary_targets_pyramid <= 0.1] = 0\n","        \n","        \n","        if boundary_logits.shape[-1] != boundary_targets.shape[-1]:\n","            boundary_logits = F.interpolate(\n","                boundary_logits, boundary_targets.shape[2:], mode='bilinear', align_corners=True)\n","        \n","        bce_loss = F.binary_cross_entropy_with_logits(boundary_logits, boudary_targets_pyramid)\n","        dice_loss = dice_loss_func(torch.sigmoid(boundary_logits), boudary_targets_pyramid)\n","        return bce_loss,  dice_loss\n","\n","    def get_params(self):\n","        wd_params, nowd_params = [], []\n","        for name, module in self.named_modules():\n","                nowd_params += list(module.parameters())\n","        return nowd_params"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OpE2HElyOJB3"},"outputs":[],"source":["class Optimizer(object):\n","    def __init__(self, model, loss, lr0, momentum, wd, warmup_steps, \n","                 warmup_start_lr, max_iter, power, *args, **kwargs):\n","        self.warmup_steps = warmup_steps\n","        self.warmup_start_lr = warmup_start_lr\n","        self.lr0 = lr0\n","        self.lr = self.lr0\n","        self.max_iter = float(max_iter)\n","        self.power = power\n","        self.it = 0\n","        # wd_params, nowd_params = model.get_params() # , lr_mul_wd_params, lr_mul_nowd_params\n","        loss_nowd_params = loss.get_params()\n","        #---------------------------------------------------------------------------\n","        #---------------------------------------------------------------------------\n","        #---------------------------------------------------------------------------\n","        param_list = [\n","                {'params': model.parameters()},\n","                {'params': loss_nowd_params}]\n","        self.optim = torch.optim.SGD(\n","                param_list,\n","                # model.parameters(),\n","                lr = lr0,\n","                momentum = momentum,\n","                weight_decay = wd)\n","        self.warmup_factor = (self.lr0/self.warmup_start_lr)**(1./self.warmup_steps)\n","\n","    def get_lr(self):\n","        if self.it <= self.warmup_steps:\n","            lr = self.warmup_start_lr*(self.warmup_factor**self.it)\n","        else:\n","            factor = (1-(self.it-self.warmup_steps)/(self.max_iter-self.warmup_steps))**self.power\n","            lr = self.lr0 * factor\n","        return lr\n","\n","    def step(self):\n","        self.lr = self.get_lr()\n","        for pg in self.optim.param_groups:\n","            if pg.get('lr_mul', False):\n","                pg['lr'] = self.lr * 10\n","            else:\n","                pg['lr'] = self.lr\n","        if self.optim.defaults.get('lr_mul', False):\n","            self.optim.defaults['lr'] = self.lr * 10\n","        else:\n","            self.optim.defaults['lr'] = self.lr\n","        self.it += 1\n","        self.optim.step()\n","        if self.it == self.warmup_steps+2:\n","            logger.info('==> warmup done, start to implement poly lr strategy')\n","    \n","    def get_state(self):\n","        return {\n","            'warmup_steps': self.warmup_steps,\n","            'warmup_start_lr': self.warmup_start_lr,\n","            'lr0': self.lr0,\n","            'lr': self.lr,\n","            'max_iter': self.max_iter,\n","            'power': self.power, \n","            'it': self.it,\n","            'optim_state': self.optim.state_dict(),\n","            'warmup_factor': self.warmup_factor\n","        }\n","\n","    def load_state(self, state):\n","        self.warmup_steps = state.get('warmup_steps')\n","        self.warmup_start_lr = state.get('warmup_start_lr')\n","        self.lr0 = state.get('lr0')\n","        self.lr = state.get('lr')\n","        self.max_iter = state.get('max_iter')\n","        self.power = state.get('power')\n","        self.it = state.get('it')\n","        self.optim.load_state_dict(state.get('optim_state'))\n","        self.warmup_factor = state.get('warmup_factor')\n","\n","\n","    def zero_grad(self):\n","        self.optim.zero_grad()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"L-4mDzEJUx7x"},"outputs":[],"source":["score_thres = 0.7\n","n_img_per_gpu = 8\n","cropsize = (512, 1024)\n","n_min = n_img_per_gpu*cropsize[0]*cropsize[1]//32\n","ignore_idx=255"]},{"cell_type":"markdown","metadata":{"id":"o-tF2L-AXDcn"},"source":["---\n","## Dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":257,"status":"ok","timestamp":1648018508385,"user":{"displayName":"Maxim Dobrokhvalov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GivhSqWinIWPCnla4i9mS0iTldWMUfolXP7x1EL=s64","userId":"05960264113093771023"},"user_tz":-180},"id":"rUhwVh6gXReD","outputId":"041dedec-85b3-4413-ffe2-6c837a56a623"},"outputs":[{"output_type":"stream","name":"stdout","text":["--2022-03-23 06:55:07--  https://raw.githubusercontent.com/MichaelFan01/STDC-Seg/master/cityscapes_info.json\n","Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.108.133, 185.199.109.133, ...\n","Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 7412 (7.2K) [text/plain]\n","Saving to: ‘cityscapes_info.json’\n","\n","\rcityscapes_info.jso   0%[                    ]       0  --.-KB/s               \rcityscapes_info.jso 100%[===================>]   7.24K  --.-KB/s    in 0s      \n","\n","2022-03-23 06:55:08 (45.0 MB/s) - ‘cityscapes_info.json’ saved [7412/7412]\n","\n"]}],"source":["!wget https://raw.githubusercontent.com/MichaelFan01/STDC-Seg/master/cityscapes_info.json"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_hLh2hCJPJsj"},"outputs":[],"source":["from PIL import Image\n","import PIL.ImageEnhance as ImageEnhance\n","import random\n","import numpy as np\n","\n","\n","class RandomCrop(object):\n","    def __init__(self, size, *args, **kwargs):\n","        self.size = size\n","\n","    def __call__(self, im_lb):\n","        im = im_lb['im']\n","        lb = im_lb['lb']\n","        assert im.size == lb.size\n","        W, H = self.size\n","        w, h = im.size\n","\n","        if (W, H) == (w, h): return dict(im=im, lb=lb)\n","        if w < W or h < H:\n","            scale = float(W) / w if w < h else float(H) / h\n","            w, h = int(scale * w + 1), int(scale * h + 1)\n","            im = im.resize((w, h), Image.BILINEAR)\n","            lb = lb.resize((w, h), Image.NEAREST)\n","        sw, sh = random.random() * (w - W), random.random() * (h - H)\n","        crop = int(sw), int(sh), int(sw) + W, int(sh) + H\n","        return dict(\n","                im = im.crop(crop),\n","                lb = lb.crop(crop)\n","                    )\n","\n","\n","class HorizontalFlip(object):\n","    def __init__(self, p=0.5, *args, **kwargs):\n","        self.p = p\n","\n","    def __call__(self, im_lb):\n","        if random.random() > self.p:\n","            return im_lb\n","        else:\n","            im = im_lb['im']\n","            lb = im_lb['lb']\n","            return dict(im = im.transpose(Image.FLIP_LEFT_RIGHT),\n","                        lb = lb.transpose(Image.FLIP_LEFT_RIGHT),\n","                    )\n","\n","\n","class RandomScale(object):\n","    def __init__(self, scales=(1, ), *args, **kwargs):\n","        self.scales = scales\n","        # print('scales: ', scales)\n","\n","    def __call__(self, im_lb):\n","        im = im_lb['im']\n","        lb = im_lb['lb']\n","        W, H = im.size\n","        scale = random.choice(self.scales)\n","        # scale = np.random.uniform(min(self.scales), max(self.scales))\n","        w, h = int(W * scale), int(H * scale)\n","        return dict(im = im.resize((w, h), Image.BILINEAR),\n","                    lb = lb.resize((w, h), Image.NEAREST),\n","                )\n","\n","\n","class ColorJitter(object):\n","    def __init__(self, brightness=None, contrast=None, saturation=None, *args, **kwargs):\n","        if not brightness is None and brightness>0:\n","            self.brightness = [max(1-brightness, 0), 1+brightness]\n","        if not contrast is None and contrast>0:\n","            self.contrast = [max(1-contrast, 0), 1+contrast]\n","        if not saturation is None and saturation>0:\n","            self.saturation = [max(1-saturation, 0), 1+saturation]\n","\n","    def __call__(self, im_lb):\n","        im = im_lb['im']\n","        lb = im_lb['lb']\n","        r_brightness = random.uniform(self.brightness[0], self.brightness[1])\n","        r_contrast = random.uniform(self.contrast[0], self.contrast[1])\n","        r_saturation = random.uniform(self.saturation[0], self.saturation[1])\n","        im = ImageEnhance.Brightness(im).enhance(r_brightness)\n","        im = ImageEnhance.Contrast(im).enhance(r_contrast)\n","        im = ImageEnhance.Color(im).enhance(r_saturation)\n","        return dict(im = im,\n","                    lb = lb,\n","                )\n","\n","\n","class MultiScale(object):\n","    def __init__(self, scales):\n","        self.scales = scales\n","\n","    def __call__(self, img):\n","        W, H = img.size\n","        sizes = [(int(W*ratio), int(H*ratio)) for ratio in self.scales]\n","        imgs = []\n","        [imgs.append(img.resize(size, Image.BILINEAR)) for size in sizes]\n","        return imgs\n","\n","\n","class Compose(object):\n","    def __init__(self, do_list):\n","        self.do_list = do_list\n","\n","    def __call__(self, im_lb):\n","        for comp in self.do_list:\n","            im_lb = comp(im_lb)\n","        return im_lb"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"c88kJt45PP93"},"outputs":[],"source":["import torch\n","from torch.utils.data import Dataset, DataLoader\n","import torchvision.transforms as transforms\n","\n","import os.path as osp\n","import os\n","from PIL import Image\n","import numpy as np\n","import json\n","\n","\n","\n","class CityScapes(Dataset):\n","    def __init__(self, rootpth, cropsize=(640, 480), mode='train', \n","    randomscale=(0.125, 0.25, 0.375, 0.5, 0.675, 0.75, 0.875, 1.0, 1.25, 1.5), *args, **kwargs):\n","        super(CityScapes, self).__init__(*args, **kwargs)\n","        assert mode in ('train', 'val', 'test', 'trainval')\n","        self.mode = mode\n","        print('self.mode', self.mode)\n","        self.ignore_lb = 255\n","\n","        with open('./cityscapes_info.json', 'r') as fr:\n","            labels_info = json.load(fr)\n","        self.lb_map = {el['id']: el['trainId'] for el in labels_info}\n","        \n","\n","        ## parse img directory\n","        self.imgs = {}\n","        imgnames = []\n","        impth = osp.join(rootpth, 'leftImg8bit', mode)\n","        folders = os.listdir(impth)\n","        for fd in folders:\n","            fdpth = osp.join(impth, fd)\n","            im_names = os.listdir(fdpth)\n","            names = [el.replace('_leftImg8bit.png', '') for el in im_names]\n","            impths = [osp.join(fdpth, el) for el in im_names]\n","            imgnames.extend(names)\n","            self.imgs.update(dict(zip(names, impths)))\n","\n","        ## parse gt directory\n","        self.labels = {}\n","        gtnames = []\n","        gtpth = osp.join(rootpth, 'gtFine', mode)\n","        folders = os.listdir(gtpth)\n","        for fd in folders:\n","            fdpth = osp.join(gtpth, fd)\n","            lbnames = os.listdir(fdpth)\n","            lbnames = [el for el in lbnames if 'labelIds' in el]\n","            names = [el.replace('_gtFine_labelIds.png', '') for el in lbnames]\n","            lbpths = [osp.join(fdpth, el) for el in lbnames]\n","            gtnames.extend(names)\n","            self.labels.update(dict(zip(names, lbpths)))\n","\n","        self.imnames = imgnames\n","        self.len = len(self.imnames)\n","        print('self.len', self.mode, self.len)\n","        assert set(imgnames) == set(gtnames)\n","        assert set(self.imnames) == set(self.imgs.keys())\n","        assert set(self.imnames) == set(self.labels.keys())\n","\n","        ## pre-processing\n","        self.to_tensor = transforms.Compose([\n","            transforms.ToTensor(),\n","            transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225)),\n","            ])\n","        self.trans_train = Compose([\n","            ColorJitter(\n","                brightness = 0.5,\n","                contrast = 0.5,\n","                saturation = 0.5),\n","            HorizontalFlip(),\n","            RandomScale(randomscale),\n","            RandomCrop(cropsize)\n","            ])\n","\n","\n","    def __getitem__(self, idx):\n","        fn  = self.imnames[idx]\n","        impth = self.imgs[fn]\n","        lbpth = self.labels[fn]\n","        img = Image.open(impth).convert('RGB')\n","        label = Image.open(lbpth)\n","        if self.mode == 'train' or self.mode == 'trainval':\n","            im_lb = dict(im = img, lb = label)\n","            im_lb = self.trans_train(im_lb)\n","            img, label = im_lb['im'], im_lb['lb']\n","        img = self.to_tensor(img)\n","        label = np.array(label).astype(np.int64)[np.newaxis, :]\n","        label = self.convert_labels(label)\n","        return img, label\n","\n","\n","    def __len__(self):\n","        return self.len\n","\n","\n","    def convert_labels(self, label):\n","        for k, v in self.lb_map.items():\n","            label[label == k] = v\n","        return label"]},{"cell_type":"code","source":["init = [(1, 1), (1, 1), (2, 2), (2, 1), (4, 2), (4, 1), (8, 1), (8, 1)]\n","model = STDC_dilated(init)"],"metadata":{"id":"dM-abjbFxCUk"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":18965,"status":"ok","timestamp":1648018528177,"user":{"displayName":"Maxim Dobrokhvalov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GivhSqWinIWPCnla4i9mS0iTldWMUfolXP7x1EL=s64","userId":"05960264113093771023"},"user_tz":-180},"id":"CdTbxumgrAqo","outputId":"3d7757e0-f5cc-45ea-de37-0660d9804bf3"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"87f6J6wdXxpA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1648018554273,"user_tz":-180,"elapsed":26118,"user":{"displayName":"Maxim Dobrokhvalov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GivhSqWinIWPCnla4i9mS0iTldWMUfolXP7x1EL=s64","userId":"05960264113093771023"}},"outputId":"8d65aa33-bd75-4c48-b7c2-c336175c42af"},"outputs":[{"output_type":"stream","name":"stdout","text":["self.mode train\n","self.len train 2975\n","self.mode val\n","self.len val 500\n"]}],"source":["dspth = '/content/drive/MyDrive/RnD/datasets/'\n","cfg_data = {\n","    'dataset': 'cityscapes',\n","    'train_split': 'train',\n","    'val_split': 'val',\n","    'img_rows': cropsize[0],\n","    'img_cols': cropsize[1],\n","    'path': dspth\n","}\n","randomscale = (0.125, 0.25, 0.375, 0.5, 0.625, 0.75, 0.875, 1.0, 1.125, 1.25, 1.375, 1.5)\n","ds = CityScapes(cfg_data['path'], cropsize=cropsize, mode='train', randomscale=randomscale)\n","# sampler = torch.utils.data.distributed.DistributedSampler(ds)\n","dl = DataLoader(ds,\n","                batch_size = batch_size,\n","                shuffle = False,\n","                # sampler = sampler,\n","                num_workers = n_workers,\n","                pin_memory = False,\n","                drop_last = True)\n","# exit(0)\n","dsval = CityScapes(cfg_data['path'], mode='val', randomscale=randomscale)\n","# sampler_val = torch.utils.data.distributed.DistributedSampler(dsval)\n","dlval = DataLoader(dsval,\n","                batch_size = 2,\n","                shuffle = False,\n","                # sampler = sampler_val,\n","                num_workers = n_workers,\n","                drop_last = False)\n","\n","## model\n","ignore_idx = 255"]},{"cell_type":"markdown","metadata":{"id":"csU-R0brNqti"},"source":["---\n","# Preparing for train"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"q_MVKWyjNwFH"},"outputs":[],"source":["best_iou = -100.0\n","flag = True\n","loss_all = 0\n","loss_n = 0"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2GqMaMb8PBiV"},"outputs":[],"source":["def get_logger(logdir):\n","    logger = logging.getLogger(\"DR_test\")\n","    ts = str(datetime.now()).split(\".\")[0].replace(\" \", \"_\")\n","    ts = ts.replace(\":\", \"_\").replace(\"-\", \"_\")\n","    file_path = os.path.join(logdir, \"run_{}.log\".format(ts))\n","    hdlr = logging.FileHandler(file_path)\n","    formatter = logging.Formatter(\"%(asctime)s %(levelname)s %(message)s\")\n","    hdlr.setFormatter(formatter)\n","    logger.addHandler(hdlr)\n","    logger.setLevel(logging.INFO)\n","    return logger"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OCjt4GHxQV-S","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1648018555929,"user_tz":-180,"elapsed":1687,"user":{"displayName":"Maxim Dobrokhvalov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GivhSqWinIWPCnla4i9mS0iTldWMUfolXP7x1EL=s64","userId":"05960264113093771023"}},"outputId":"9df5ad62-8a2a-4564-b3bd-4dbf7aba65c2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Cloning into 'FCHarDNet'...\n","remote: Enumerating objects: 130, done.\u001b[K\n","remote: Counting objects: 100% (13/13), done.\u001b[K\n","remote: Compressing objects: 100% (12/12), done.\u001b[K\n","remote: Total 130 (delta 2), reused 7 (delta 1), pack-reused 117\u001b[K\n","Receiving objects: 100% (130/130), 9.10 MiB | 22.95 MiB/s, done.\n","Resolving deltas: 100% (50/50), done.\n"]}],"source":["!git clone https://github.com/PingoLH/FCHarDNet.git\n","!cp -r FCHarDNet/ptsemseg ./\n","!rm -rf FCHarDNet"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2-4aOn4dQeLT"},"outputs":[],"source":["from ptsemseg.loader import get_loader\n","from ptsemseg.metrics import runningScore, averageMeter\n","from ptsemseg.augmentations import get_composed_augmentations"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nJTlBpSmStgU"},"outputs":[],"source":["base_path = \"/content/drive/MyDrive/RnD/runs/STDC\"\n","model_modification = 'STDC_dilated_fov_3319'\n","model_modification_path = os.path.join(base_path, model_modification)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TAoSxPyeaFio","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1648018556533,"user_tz":-180,"elapsed":248,"user":{"displayName":"Maxim Dobrokhvalov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GivhSqWinIWPCnla4i9mS0iTldWMUfolXP7x1EL=s64","userId":"05960264113093771023"}},"outputId":"248f19ef-ec32-4569-d72f-e5d83de2d57c"},"outputs":[{"output_type":"stream","name":"stdout","text":["RUNDIR: /content/drive/MyDrive/RnD/runs/STDC/STDC_dilated_fov_3999/2022-03-23 06:55:55\n"]}],"source":["logdir = os.path.join(model_modification_path, str(datetime.fromtimestamp(int(time.time()))))\n","writer = SummaryWriter(log_dir=logdir)\n","\n","print(\"RUNDIR: {}\".format(logdir))\n","\n","logger = get_logger(logdir)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nDPzLJpLP7au"},"outputs":[],"source":["# Setup seeds\n","torch.manual_seed(1337)\n","torch.cuda.manual_seed(1337)\n","np.random.seed(1337)\n","random.seed(1337)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"G95g0arBR1AY"},"outputs":[],"source":["running_metrics_val = runningScore(n_classes)\n","\n","init = [(1, 1), (1, 1), (2, 2), (2, 1), (4, 2), (4, 1), (8, 1), (8, 1)]\n","model = STDC_dilated(init)\n","\n","def weights_init(m):\n","    if isinstance(m, nn.Conv2d):\n","        nn.init.xavier_normal_(m.weight)\n","\n","model = torch.nn.DataParallel(model, device_ids=range(torch.cuda.device_count()))\n","model.apply(weights_init)\n","pass"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"P_5wFQ0UVnHt"},"outputs":[],"source":["# optimizer init data\n","momentum = 0.9\n","weight_decay = 5e-4\n","lr_start = 1e-2\n","power = 0.9\n","warmup_steps = 1000\n","warmup_start_lr = 1e-5\n","epoch_iteration = len(ds) // batch_size\n","max_epoch = 484\n","max_iter = max_epoch * epoch_iteration"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rg_faMQHOnMZ"},"outputs":[],"source":["start_epoch = 0\n","it = 0\n","local_max_epoch = start_epoch + 6 if start_epoch + 6 < max_epoch else max_epoch"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nfsksqZNg3TM"},"outputs":[],"source":["criteria_ffm = OhemCELoss(thresh=score_thres, n_min=n_min, ignore_lb=ignore_idx)    # out1\n","boundary_loss_func = DetailAggregateLoss()                                          # out3\n","criteria_val = OhemCELoss(thresh=score_thres, n_min=n_min, ignore_lb=ignore_idx)    # out1 \n","val_loss_meter = averageMeter()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"SFawk_jCVuJg"},"outputs":[],"source":["optim = Optimizer(\n","            model = model.module,\n","            loss = boundary_loss_func,\n","            lr0 = lr_start,\n","            momentum = momentum,\n","            wd = weight_decay,\n","            warmup_steps = warmup_steps,\n","            warmup_start_lr = warmup_start_lr,\n","            max_iter = max_iter,\n","            power = power)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"gcCTdTNiWhH3"},"outputs":[],"source":["loss_avg = []\n","loss_boundery_bce = []\n","loss_boundery_dice = []"]},{"cell_type":"markdown","metadata":{"id":"2aFTxfMXSqw3"},"source":["---\n","## Restore state"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kuw_ClrzSqJM"},"outputs":[],"source":["runs = sorted(os.listdir(model_modification_path), reverse=True)\n","best_path = None\n","last_path = None\n","for run in runs:\n","    tmp_base = os.path.join(model_modification_path, run)\n","    model_name = \"{}_{}\".format(model_arch, cfg_data['dataset'])\n","    checkpoint = os.path.join(tmp_base, model_name+'_checkpoint.pkl')\n","    best = os.path.join(tmp_base, model_name+'_best_model.pkl')\n","    if not last_path and os.path.exists(checkpoint):\n","        last_path = checkpoint\n","    if not best_path and os.path.exists(best):\n","        best_path = best\n","    if last_path and best_path:\n","        break"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1jc6LeN9TOCq"},"outputs":[],"source":["loaded = torch.load(last_path)\n","best_iou_arrc = torch.load(best_path)\n","model_state = loaded.get('model_state')\n","\n","optimizer_state = loaded.get('optimizer_state')\n","start_epoch = loaded.get('epoch') + 1\n","local_max_epoch = start_epoch + 2\n","\n","best_iou = best_iou_arrc.get('best_iou')\n","i = 0\n","flag = True\n","loss_all = 0\n","loss_n = 0\n","\n","model.load_state_dict(model_state)\n","optim.load_state(optimizer_state)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"e4HbAmnvVMFA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1648018566983,"user_tz":-180,"elapsed":18,"user":{"displayName":"Maxim Dobrokhvalov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GivhSqWinIWPCnla4i9mS0iTldWMUfolXP7x1EL=s64","userId":"05960264113093771023"}},"outputId":"31b0ef6d-a820-4f49-b1bb-8aae47fe0dbc"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(48, 50, 0.42888084423905515)"]},"metadata":{},"execution_count":37}],"source":["file_ = list(filter(lambda x: x.endswith('.log'), os.listdir(logdir)))[0]\n","file_ = os.path.join(logdir, file_)\n","if not flag and osp.isfile(file_):\n","    with open(file_, \"r\") as f:\n","        str_ = f.readlines()[-24]\n","        st__, end__ = str_.find('Epoch') + 6, str_.find(' Iter')\n","        if st__ > -1 and end__ > -1 and local_max_epoch - 1 == int(str_[st__:end__]):\n","            start_epoch = local_max_epoch\n","            local_max_epoch += 12\n","\n","\n","start_epoch, local_max_epoch, best_iou"]},{"cell_type":"markdown","metadata":{"id":"1ZjxXbpI_MDX"},"source":["## Training"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HuAUlVp7XTSc","outputId":"e6af1c4d-0d44-4583-cdf7-fc24e4d01cfe","executionInfo":{"status":"ok","timestamp":1648030743946,"user_tz":-180,"elapsed":12126619,"user":{"displayName":"Maxim Dobrokhvalov","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GivhSqWinIWPCnla4i9mS0iTldWMUfolXP7x1EL=s64","userId":"05960264113093771023"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["loss/train_loss 2.215222120285034 10\n","loss/train_loss 1.6123428344726562 20\n","loss/train_loss 1.8636270761489868 30\n","loss/train_loss 1.8453680276870728 40\n","loss/train_loss 1.8716280460357666 50\n","loss/train_loss 2.1711292266845703 60\n","loss/train_loss 1.8516502380371094 70\n","loss/train_loss 1.7392125129699707 80\n","loss/train_loss 1.9524307250976562 90\n","loss/train_loss 1.7972493171691895 100\n","loss/train_loss 1.6524053812026978 110\n","loss/train_loss 2.1888880729675293 120\n","loss/train_loss 1.824354648590088 130\n","loss/train_loss 1.8823046684265137 140\n","loss/train_loss 1.9451643228530884 150\n","loss/train_loss 1.9407240152359009 160\n","loss/train_loss 1.8094360828399658 170\n","loss/train_loss 1.95133638381958 180\n","loss/train_loss 1.7997570037841797 190\n","loss/train_loss 1.9034950733184814 200\n","loss/train_loss 1.769835352897644 210\n","loss/train_loss 2.3221662044525146 220\n","loss/train_loss 1.7864528894424438 230\n","loss/train_loss 1.772383689880371 240\n","loss/train_loss 2.1814308166503906 250\n","loss/train_loss 2.119511604309082 260\n","loss/train_loss 1.6924391984939575 270\n","loss/train_loss 1.9957315921783447 280\n","loss/train_loss 2.149062156677246 290\n","loss/train_loss 2.3101043701171875 300\n","loss/train_loss 2.041363000869751 310\n","loss/train_loss 2.0307202339172363 320\n","loss/train_loss 1.8493722677230835 330\n","loss/train_loss 1.7822004556655884 340\n","loss/train_loss 2.100458860397339 350\n","loss/train_loss 1.6293506622314453 360\n","loss/train_loss 1.8310964107513428 370\n","validation\n","50\n","100\n","150\n","200\n","250\n","loss/val_loss 1.1876828181743622 371\n","Overall Acc: \t 0.8973571731332889\n","val_metrics/Overall Acc: \t 0.8973571731332889 371\n","Mean Acc : \t 0.5302187026158712\n","val_metrics/Mean Acc : \t 0.5302187026158712 371\n","FreqW Acc : \t 0.8260738865410938\n","val_metrics/FreqW Acc : \t 0.8260738865410938 371\n","Mean IoU : \t 0.4318689078325123\n","val_metrics/Mean IoU : \t 0.4318689078325123 371\n","val_metrics/cls_0 0.9430142496313186 371\n","val_metrics/cls_1 0.6055991467439197 371\n","val_metrics/cls_2 0.824745379162457 371\n","val_metrics/cls_3 0.08693738406834543 371\n","val_metrics/cls_4 0.262971570094752 371\n","val_metrics/cls_5 0.3297160941043569 371\n","val_metrics/cls_6 0.22893657040762252 371\n","val_metrics/cls_7 0.3307048873681069 371\n","val_metrics/cls_8 0.8538246498084259 371\n","val_metrics/cls_9 0.4219301911104525 371\n","val_metrics/cls_10 0.9102286133317212 371\n","val_metrics/cls_11 0.535591662489287 371\n","val_metrics/cls_12 0.08369886321321293 371\n","val_metrics/cls_13 0.8153969142544418 371\n","val_metrics/cls_14 0.0049499503412410925 371\n","val_metrics/cls_15 0.36402671819664534 371\n","val_metrics/cls_16 0.052355105737502454 371\n","val_metrics/cls_17 0.06783975257873863 371\n","val_metrics/cls_18 0.48304154617518774 371\n","loss/train_loss 1.782625675201416 10\n","loss/train_loss 1.6978667974472046 20\n","loss/train_loss 2.057020425796509 30\n","loss/train_loss 1.8305715322494507 40\n","loss/train_loss 1.9709312915802002 50\n","loss/train_loss 2.2402424812316895 60\n","loss/train_loss 1.8646892309188843 70\n","loss/train_loss 1.9141621589660645 80\n","loss/train_loss 2.135011911392212 90\n","loss/train_loss 1.6769806146621704 100\n","loss/train_loss 1.5595310926437378 110\n","loss/train_loss 1.7098300457000732 120\n","loss/train_loss 1.7226933240890503 130\n","loss/train_loss 1.9196207523345947 140\n","loss/train_loss 1.925431251525879 150\n","loss/train_loss 1.7643704414367676 160\n","loss/train_loss 2.008497476577759 170\n","loss/train_loss 2.0790023803710938 180\n","loss/train_loss 1.7366915941238403 190\n","loss/train_loss 1.930374026298523 200\n","loss/train_loss 1.9207643270492554 210\n","loss/train_loss 2.051140785217285 220\n","loss/train_loss 1.7960633039474487 230\n","loss/train_loss 1.6067545413970947 240\n","loss/train_loss 1.8916164636611938 250\n","loss/train_loss 1.7322635650634766 260\n","loss/train_loss 1.7011570930480957 270\n","loss/train_loss 1.9452099800109863 280\n","loss/train_loss 2.1317498683929443 290\n","loss/train_loss 2.336308717727661 300\n","loss/train_loss 1.5821094512939453 310\n","loss/train_loss 1.9836781024932861 320\n","loss/train_loss 2.01179575920105 330\n","loss/train_loss 1.945845127105713 340\n","loss/train_loss 1.6886730194091797 350\n","loss/train_loss 2.0497782230377197 360\n","loss/train_loss 1.6696633100509644 370\n","validation\n","50\n","100\n","150\n","200\n","250\n","loss/val_loss 1.3224776997566223 371\n","Overall Acc: \t 0.8602950883359998\n","val_metrics/Overall Acc: \t 0.8602950883359998 371\n","Mean Acc : \t 0.4717568826885733\n","val_metrics/Mean Acc : \t 0.4717568826885733 371\n","FreqW Acc : \t 0.7724402292232517\n","val_metrics/FreqW Acc : \t 0.7724402292232517 371\n","Mean IoU : \t 0.3620333207327339\n","val_metrics/Mean IoU : \t 0.3620333207327339 371\n","val_metrics/cls_0 0.9062008013285525 371\n","val_metrics/cls_1 0.5853526564787561 371\n","val_metrics/cls_2 0.7737778719107102 371\n","val_metrics/cls_3 0.09642878312256295 371\n","val_metrics/cls_4 0.23339590421889608 371\n","val_metrics/cls_5 0.22256749418172636 371\n","val_metrics/cls_6 0.07562950274364068 371\n","val_metrics/cls_7 0.32949261898210186 371\n","val_metrics/cls_8 0.8051140510134064 371\n","val_metrics/cls_9 0.28386649854705504 371\n","val_metrics/cls_10 0.8679069963149789 371\n","val_metrics/cls_11 0.4087061551764592 371\n","val_metrics/cls_12 0.0070316084223850635 371\n","val_metrics/cls_13 0.6478654024001449 371\n","val_metrics/cls_14 0.02923805768105127 371\n","val_metrics/cls_15 0.26144142955908656 371\n","val_metrics/cls_16 0.042091803305823884 371\n","val_metrics/cls_17 0.005447400730293402 371\n","val_metrics/cls_18 0.2970780578043131 371\n","loss/train_loss 1.7821547985076904 10\n","loss/train_loss 1.72809898853302 20\n","loss/train_loss 2.1621792316436768 30\n","loss/train_loss 1.890777826309204 40\n","loss/train_loss 1.9541758298873901 50\n","loss/train_loss 1.8340867757797241 60\n","loss/train_loss 1.8728246688842773 70\n","loss/train_loss 2.0024514198303223 80\n","loss/train_loss 2.1678452491760254 90\n","loss/train_loss 1.7196624279022217 100\n","loss/train_loss 1.8430070877075195 110\n","loss/train_loss 1.9019842147827148 120\n","loss/train_loss 1.837837815284729 130\n","loss/train_loss 1.5667896270751953 140\n","loss/train_loss 1.848703145980835 150\n","loss/train_loss 1.8609883785247803 160\n","loss/train_loss 2.228178024291992 170\n","loss/train_loss 1.9351859092712402 180\n","loss/train_loss 1.7502591609954834 190\n","loss/train_loss 1.911689043045044 200\n","loss/train_loss 1.7948006391525269 210\n","loss/train_loss 2.1368322372436523 220\n","loss/train_loss 1.6532526016235352 230\n","loss/train_loss 1.7702314853668213 240\n","loss/train_loss 2.1806955337524414 250\n","loss/train_loss 1.9419093132019043 260\n","loss/train_loss 1.717167615890503 270\n","loss/train_loss 1.943078637123108 280\n","loss/train_loss 1.9143688678741455 290\n","loss/train_loss 2.018738269805908 300\n","loss/train_loss 2.1266186237335205 310\n","loss/train_loss 1.9256724119186401 320\n","loss/train_loss 1.7590644359588623 330\n","loss/train_loss 1.8959546089172363 340\n","loss/train_loss 1.8620402812957764 350\n","loss/train_loss 1.7346303462982178 360\n","loss/train_loss 1.8406336307525635 370\n","validation\n","50\n","100\n","150\n","200\n","250\n","loss/val_loss 1.1445662105083465 371\n","Overall Acc: \t 0.8999460882189476\n","val_metrics/Overall Acc: \t 0.8999460882189476 371\n","Mean Acc : \t 0.5262116841887611\n","val_metrics/Mean Acc : \t 0.5262116841887611 371\n","FreqW Acc : \t 0.8276012369975623\n","val_metrics/FreqW Acc : \t 0.8276012369975623 371\n","Mean IoU : \t 0.44461172388986575\n","val_metrics/Mean IoU : \t 0.44461172388986575 371\n","val_metrics/cls_0 0.9391282405017807 371\n","val_metrics/cls_1 0.6306523809607015 371\n","val_metrics/cls_2 0.8260361753350017 371\n","val_metrics/cls_3 0.10076783836797709 371\n","val_metrics/cls_4 0.2591097198017202 371\n","val_metrics/cls_5 0.3967727164456243 371\n","val_metrics/cls_6 0.21772754375356915 371\n","val_metrics/cls_7 0.4339688009967966 371\n","val_metrics/cls_8 0.850926119626528 371\n","val_metrics/cls_9 0.43038009697492186 371\n","val_metrics/cls_10 0.8944616486624787 371\n","val_metrics/cls_11 0.5265746464572377 371\n","val_metrics/cls_12 0.044773677205784346 371\n","val_metrics/cls_13 0.8206948224011719 371\n","val_metrics/cls_14 0.0124565438981048 371\n","val_metrics/cls_15 0.38828993799237815 371\n","val_metrics/cls_16 0.1433252216361882 371\n","val_metrics/cls_17 0.010431393326741036 371\n","val_metrics/cls_18 0.5211452295627438 371\n","loss/train_loss 1.9173080921173096 10\n","loss/train_loss 1.89066481590271 20\n","loss/train_loss 1.935826301574707 30\n","loss/train_loss 1.9750303030014038 40\n","loss/train_loss 1.9555246829986572 50\n","loss/train_loss 2.084970474243164 60\n","loss/train_loss 1.893867015838623 70\n","loss/train_loss 1.658329963684082 80\n","loss/train_loss 1.6218550205230713 90\n","loss/train_loss 1.639468789100647 100\n","loss/train_loss 1.553011178970337 110\n","loss/train_loss 2.2766849994659424 120\n","loss/train_loss 1.65790593624115 130\n","loss/train_loss 2.0228617191314697 140\n","loss/train_loss 2.1288037300109863 150\n","loss/train_loss 1.71540367603302 160\n","loss/train_loss 2.3600239753723145 170\n","loss/train_loss 2.5145063400268555 180\n","loss/train_loss 1.6020914316177368 190\n","loss/train_loss 1.782724380493164 200\n","loss/train_loss 1.7916035652160645 210\n","loss/train_loss 2.161031484603882 220\n","loss/train_loss 1.737741231918335 230\n","loss/train_loss 1.7958991527557373 240\n","loss/train_loss 2.129659652709961 250\n","loss/train_loss 1.831095576286316 260\n","loss/train_loss 1.865024209022522 270\n","loss/train_loss 1.943739414215088 280\n","loss/train_loss 1.938184142112732 290\n","loss/train_loss 1.9301354885101318 300\n","loss/train_loss 1.959783673286438 310\n","loss/train_loss 2.0389583110809326 320\n","loss/train_loss 1.9116544723510742 330\n","loss/train_loss 2.126101016998291 340\n","loss/train_loss 1.7760100364685059 350\n","loss/train_loss 1.710726022720337 360\n","loss/train_loss 1.7381675243377686 370\n","validation\n","50\n","100\n","150\n","200\n","250\n","loss/val_loss 1.1196846399307252 371\n","Overall Acc: \t 0.8976974160005187\n","val_metrics/Overall Acc: \t 0.8976974160005187 371\n","Mean Acc : \t 0.5410403156138708\n","val_metrics/Mean Acc : \t 0.5410403156138708 371\n","FreqW Acc : \t 0.8258788106029059\n","val_metrics/FreqW Acc : \t 0.8258788106029059 371\n","Mean IoU : \t 0.4383227740402986\n","val_metrics/Mean IoU : \t 0.4383227740402986 371\n","val_metrics/cls_0 0.9329986357701454 371\n","val_metrics/cls_1 0.6105896440128864 371\n","val_metrics/cls_2 0.8249874274464766 371\n","val_metrics/cls_3 0.17050696116819392 371\n","val_metrics/cls_4 0.2898347555306053 371\n","val_metrics/cls_5 0.31056142679355647 371\n","val_metrics/cls_6 0.16119889436833043 371\n","val_metrics/cls_7 0.46873025721295564 371\n","val_metrics/cls_8 0.8602846571415558 371\n","val_metrics/cls_9 0.37043699939696106 371\n","val_metrics/cls_10 0.8696963415234195 371\n","val_metrics/cls_11 0.5184556559162824 371\n","val_metrics/cls_12 0.005672489109426783 371\n","val_metrics/cls_13 0.8555251761424656 371\n","val_metrics/cls_14 0.019957310907729092 371\n","val_metrics/cls_15 0.3254802346205221 371\n","val_metrics/cls_16 0.19508327144937476 371\n","val_metrics/cls_17 0.004367709708592506 371\n","val_metrics/cls_18 0.5337648585461939 371\n","loss/train_loss 1.8991106748580933 10\n","loss/train_loss 1.660670280456543 20\n","loss/train_loss 2.0240581035614014 30\n","loss/train_loss 1.6615676879882812 40\n","loss/train_loss 1.841249704360962 50\n","loss/train_loss 2.0853323936462402 60\n","loss/train_loss 1.7610907554626465 70\n","loss/train_loss 1.7079201936721802 80\n","loss/train_loss 2.2140326499938965 90\n","loss/train_loss 1.5979363918304443 100\n","loss/train_loss 1.9247984886169434 110\n","loss/train_loss 2.0295732021331787 120\n","loss/train_loss 1.8897074460983276 130\n","loss/train_loss 1.5976685285568237 140\n","loss/train_loss 1.8755130767822266 150\n","loss/train_loss 1.6851966381072998 160\n","loss/train_loss 1.998340129852295 170\n","loss/train_loss 2.0230116844177246 180\n","loss/train_loss 1.7888669967651367 190\n","loss/train_loss 1.9991116523742676 200\n","loss/train_loss 1.7528573274612427 210\n","loss/train_loss 1.9529656171798706 220\n","loss/train_loss 1.9135465621948242 230\n","loss/train_loss 1.6424928903579712 240\n","loss/train_loss 2.1009697914123535 250\n","loss/train_loss 1.7888362407684326 260\n","loss/train_loss 1.7317955493927002 270\n","loss/train_loss 1.8159592151641846 280\n","loss/train_loss 2.0247151851654053 290\n","loss/train_loss 2.022728681564331 300\n","loss/train_loss 1.9329683780670166 310\n","loss/train_loss 1.7778286933898926 320\n","loss/train_loss 2.296628475189209 330\n","loss/train_loss 1.764914631843567 340\n","loss/train_loss 2.027714252471924 350\n","loss/train_loss 1.9049787521362305 360\n","loss/train_loss 1.776009202003479 370\n","validation\n","50\n","100\n","150\n","200\n","250\n","loss/val_loss 1.0572133264541625 371\n","Overall Acc: \t 0.8858387139891135\n","val_metrics/Overall Acc: \t 0.8858387139891135 371\n","Mean Acc : \t 0.5466950399366575\n","val_metrics/Mean Acc : \t 0.5466950399366575 371\n","FreqW Acc : \t 0.8106868104555001\n","val_metrics/FreqW Acc : \t 0.8106868104555001 371\n","Mean IoU : \t 0.44302074701769145\n","val_metrics/Mean IoU : \t 0.44302074701769145 371\n","val_metrics/cls_0 0.9106420295544625 371\n","val_metrics/cls_1 0.5536978094165242 371\n","val_metrics/cls_2 0.8192015581335674 371\n","val_metrics/cls_3 0.21399634418774804 371\n","val_metrics/cls_4 0.25230983022909276 371\n","val_metrics/cls_5 0.3415942798045037 371\n","val_metrics/cls_6 0.2436956569995514 371\n","val_metrics/cls_7 0.45770803174024266 371\n","val_metrics/cls_8 0.8410998717639485 371\n","val_metrics/cls_9 0.45320987513376576 371\n","val_metrics/cls_10 0.8933991923343286 371\n","val_metrics/cls_11 0.5397116036283545 371\n","val_metrics/cls_12 0.028051990952140206 371\n","val_metrics/cls_13 0.8364263029560759 371\n","val_metrics/cls_14 0.01685161161947992 371\n","val_metrics/cls_15 0.3286736983306697 371\n","val_metrics/cls_16 0.18111359820103665 371\n","val_metrics/cls_17 0.002785372752373897 371\n","val_metrics/cls_18 0.5032255355982705 371\n","loss/train_loss 1.9246232509613037 10\n","loss/train_loss 1.6216448545455933 20\n","loss/train_loss 1.9248485565185547 30\n","loss/train_loss 1.8247804641723633 40\n","loss/train_loss 1.828190803527832 50\n","loss/train_loss 2.006718635559082 60\n","loss/train_loss 1.6753400564193726 70\n","loss/train_loss 1.7189521789550781 80\n","loss/train_loss 2.220191717147827 90\n","loss/train_loss 1.7904263734817505 100\n","loss/train_loss 1.8270103931427002 110\n","loss/train_loss 2.0483601093292236 120\n","loss/train_loss 1.6595520973205566 130\n","loss/train_loss 1.715803861618042 140\n","loss/train_loss 1.956845998764038 150\n","loss/train_loss 1.8202605247497559 160\n","loss/train_loss 2.07088303565979 170\n","loss/train_loss 1.9073578119277954 180\n","loss/train_loss 1.885823369026184 190\n","loss/train_loss 1.8283467292785645 200\n","loss/train_loss 1.6684423685073853 210\n","loss/train_loss 2.14663028717041 220\n","loss/train_loss 1.79277503490448 230\n","loss/train_loss 1.5757993459701538 240\n","loss/train_loss 2.0487711429595947 250\n","loss/train_loss 1.8115043640136719 260\n","loss/train_loss 1.592421054840088 270\n","loss/train_loss 1.9879287481307983 280\n","loss/train_loss 2.0763564109802246 290\n","loss/train_loss 2.0815186500549316 300\n","loss/train_loss 1.9140493869781494 310\n","loss/train_loss 2.001749277114868 320\n","loss/train_loss 1.8756911754608154 330\n","loss/train_loss 1.7424260377883911 340\n","loss/train_loss 1.7958818674087524 350\n","loss/train_loss 1.7454673051834106 360\n","loss/train_loss 1.831264853477478 370\n","validation\n","50\n","100\n","150\n","200\n","250\n","loss/val_loss 1.0878372044563294 371\n","Overall Acc: \t 0.9014324486537152\n","val_metrics/Overall Acc: \t 0.9014324486537152 371\n","Mean Acc : \t 0.5487199353429414\n","val_metrics/Mean Acc : \t 0.5487199353429414 371\n","FreqW Acc : \t 0.831582312328902\n","val_metrics/FreqW Acc : \t 0.831582312328902 371\n","Mean IoU : \t 0.45026471937495455\n","val_metrics/Mean IoU : \t 0.45026471937495455 371\n","val_metrics/cls_0 0.9488650736315443 371\n","val_metrics/cls_1 0.6572170422532331 371\n","val_metrics/cls_2 0.825399311314068 371\n","val_metrics/cls_3 0.08447259027484988 371\n","val_metrics/cls_4 0.2701725863886495 371\n","val_metrics/cls_5 0.34219765906364946 371\n","val_metrics/cls_6 0.20618026534031458 371\n","val_metrics/cls_7 0.4571795183481779 371\n","val_metrics/cls_8 0.8452511744102107 371\n","val_metrics/cls_9 0.3669787164962527 371\n","val_metrics/cls_10 0.8977161491017132 371\n","val_metrics/cls_11 0.5661735276204574 371\n","val_metrics/cls_12 0.10962849252423307 371\n","val_metrics/cls_13 0.8286706833526699 371\n","val_metrics/cls_14 0.013861633553384411 371\n","val_metrics/cls_15 0.36607004443903174 371\n","val_metrics/cls_16 0.22947446782274308 371\n","val_metrics/cls_17 0.02957352627685054 371\n","val_metrics/cls_18 0.509947205912104 371\n","loss/train_loss 1.912055492401123 10\n","loss/train_loss 1.8705264329910278 20\n","loss/train_loss 2.069930076599121 30\n","loss/train_loss 2.040419578552246 40\n","loss/train_loss 1.9413700103759766 50\n","loss/train_loss 2.113084316253662 60\n","loss/train_loss 1.7505176067352295 70\n","loss/train_loss 1.6676864624023438 80\n","loss/train_loss 1.7279269695281982 90\n","loss/train_loss 1.6129502058029175 100\n","loss/train_loss 1.8453354835510254 110\n","loss/train_loss 1.8593605756759644 120\n","loss/train_loss 2.0719361305236816 130\n","loss/train_loss 1.8703051805496216 140\n","loss/train_loss 1.9914612770080566 150\n","loss/train_loss 1.8168985843658447 160\n","loss/train_loss 1.9928205013275146 170\n","loss/train_loss 2.1273722648620605 180\n","loss/train_loss 1.7829629182815552 190\n","loss/train_loss 1.759521484375 200\n","loss/train_loss 1.6124529838562012 210\n","loss/train_loss 2.0853044986724854 220\n","loss/train_loss 1.6861625909805298 230\n","loss/train_loss 1.620347023010254 240\n","loss/train_loss 1.9229439496994019 250\n","loss/train_loss 2.058716297149658 260\n","loss/train_loss 1.6935185194015503 270\n","loss/train_loss 1.8187346458435059 280\n","loss/train_loss 2.0316402912139893 290\n","loss/train_loss 1.9033247232437134 300\n","loss/train_loss 1.8116761445999146 310\n","loss/train_loss 2.1352922916412354 320\n","loss/train_loss 1.882012128829956 330\n","loss/train_loss 1.8067471981048584 340\n","loss/train_loss 1.9261388778686523 350\n","loss/train_loss 1.6517444849014282 360\n","loss/train_loss 1.696862816810608 370\n","validation\n","50\n","100\n","150\n","200\n","250\n","loss/val_loss 1.1434045045375825 371\n","Overall Acc: \t 0.897972588205907\n","val_metrics/Overall Acc: \t 0.897972588205907 371\n","Mean Acc : \t 0.5425755231189638\n","val_metrics/Mean Acc : \t 0.5425755231189638 371\n","FreqW Acc : \t 0.825836730437466\n","val_metrics/FreqW Acc : \t 0.825836730437466 371\n","Mean IoU : \t 0.4501341765420113\n","val_metrics/Mean IoU : \t 0.4501341765420113 371\n","val_metrics/cls_0 0.9478645679490144 371\n","val_metrics/cls_1 0.6744005401087386 371\n","val_metrics/cls_2 0.8020607356476209 371\n","val_metrics/cls_3 0.22640681745626878 371\n","val_metrics/cls_4 0.26485582921013584 371\n","val_metrics/cls_5 0.36587755507544434 371\n","val_metrics/cls_6 0.2343779989719619 371\n","val_metrics/cls_7 0.4259454845271453 371\n","val_metrics/cls_8 0.8427744649235802 371\n","val_metrics/cls_9 0.4377328022983599 371\n","val_metrics/cls_10 0.8800206869026663 371\n","val_metrics/cls_11 0.5431379392830474 371\n","val_metrics/cls_12 0.07052745099283658 371\n","val_metrics/cls_13 0.8125370932605295 371\n","val_metrics/cls_14 0.1354983588659729 371\n","val_metrics/cls_15 0.1803068204241363 371\n","val_metrics/cls_16 0.20288751601948732 371\n","val_metrics/cls_17 0.010456663460224487 371\n","val_metrics/cls_18 0.4948800289210435 371\n","loss/train_loss 1.7240755558013916 10\n","loss/train_loss 1.7790846824645996 20\n","loss/train_loss 1.868518590927124 30\n","loss/train_loss 2.158778667449951 40\n","loss/train_loss 1.7676571607589722 50\n","loss/train_loss 1.8564820289611816 60\n","loss/train_loss 1.9751620292663574 70\n","loss/train_loss 1.7202001810073853 80\n","loss/train_loss 2.318089723587036 90\n","loss/train_loss 1.737260341644287 100\n","loss/train_loss 1.6646286249160767 110\n","loss/train_loss 1.7590508460998535 120\n","loss/train_loss 1.776902437210083 130\n","loss/train_loss 1.6762912273406982 140\n","loss/train_loss 2.3322746753692627 150\n","loss/train_loss 1.5065962076187134 160\n","loss/train_loss 2.092228412628174 170\n","loss/train_loss 2.704848289489746 180\n","loss/train_loss 1.6414120197296143 190\n","loss/train_loss 1.7706074714660645 200\n","loss/train_loss 1.8694915771484375 210\n","loss/train_loss 1.8568058013916016 220\n","loss/train_loss 1.703264832496643 230\n","loss/train_loss 1.90264892578125 240\n","loss/train_loss 1.8368685245513916 250\n","loss/train_loss 2.002329111099243 260\n","loss/train_loss 1.7270292043685913 270\n","loss/train_loss 1.9885597229003906 280\n","loss/train_loss 1.8523163795471191 290\n","loss/train_loss 1.8845548629760742 300\n","loss/train_loss 2.4077606201171875 310\n","loss/train_loss 1.7117714881896973 320\n","loss/train_loss 2.1270666122436523 330\n","loss/train_loss 1.957000494003296 340\n","loss/train_loss 1.9378230571746826 350\n","loss/train_loss 1.9593324661254883 360\n","loss/train_loss 1.6548199653625488 370\n","validation\n","50\n","100\n","150\n","200\n","250\n","loss/val_loss 1.3372631316184997 371\n","Overall Acc: \t 0.846542206413463\n","val_metrics/Overall Acc: \t 0.846542206413463 371\n","Mean Acc : \t 0.5103596105546536\n","val_metrics/Mean Acc : \t 0.5103596105546536 371\n","FreqW Acc : \t 0.7820596866911967\n","val_metrics/FreqW Acc : \t 0.7820596866911967 371\n","Mean IoU : \t 0.38006301319149277\n","val_metrics/Mean IoU : \t 0.38006301319149277 371\n","val_metrics/cls_0 0.9226865211481095 371\n","val_metrics/cls_1 0.5635741074958249 371\n","val_metrics/cls_2 0.7425390693154741 371\n","val_metrics/cls_3 0.027573248811845356 371\n","val_metrics/cls_4 0.19821638090007446 371\n","val_metrics/cls_5 0.30783427934079355 371\n","val_metrics/cls_6 0.23355354779422977 371\n","val_metrics/cls_7 0.38824390312753143 371\n","val_metrics/cls_8 0.8299321262529082 371\n","val_metrics/cls_9 0.36109384540434936 371\n","val_metrics/cls_10 0.8843526105027326 371\n","val_metrics/cls_11 0.49588622424486156 371\n","val_metrics/cls_12 0.0442740010635535 371\n","val_metrics/cls_13 0.6998631650309032 371\n","val_metrics/cls_14 0.00012499044457108533 371\n","val_metrics/cls_15 0.02148314720152686 371\n","val_metrics/cls_16 0.020759483132787037 371\n","val_metrics/cls_17 0.011148912997504546 371\n","val_metrics/cls_18 0.46805768642878126 371\n","loss/train_loss 1.9258842468261719 10\n","loss/train_loss 1.8177192211151123 20\n","loss/train_loss 1.9288545846939087 30\n","loss/train_loss 2.1727468967437744 40\n","loss/train_loss 1.76289701461792 50\n","loss/train_loss 2.2634634971618652 60\n","loss/train_loss 1.7483305931091309 70\n","loss/train_loss 2.19460129737854 80\n","loss/train_loss 1.9961063861846924 90\n","loss/train_loss 1.5938127040863037 100\n","loss/train_loss 1.528627634048462 110\n","loss/train_loss 1.9119668006896973 120\n","loss/train_loss 2.2691667079925537 130\n","loss/train_loss 1.859973669052124 140\n","loss/train_loss 1.8290951251983643 150\n","loss/train_loss 1.7020902633666992 160\n","loss/train_loss 1.937727928161621 170\n","loss/train_loss 2.0866506099700928 180\n","loss/train_loss 1.6785515546798706 190\n","loss/train_loss 1.8722931146621704 200\n","loss/train_loss 1.8483047485351562 210\n","loss/train_loss 2.117771625518799 220\n","loss/train_loss 1.7212010622024536 230\n","loss/train_loss 1.713796615600586 240\n","loss/train_loss 1.9294755458831787 250\n","loss/train_loss 1.9963264465332031 260\n","loss/train_loss 1.711469054222107 270\n","loss/train_loss 1.7077968120574951 280\n","loss/train_loss 1.8676211833953857 290\n","loss/train_loss 2.0257911682128906 300\n","loss/train_loss 1.7058438062667847 310\n","loss/train_loss 1.9483258724212646 320\n","loss/train_loss 2.1938893795013428 330\n","loss/train_loss 1.7699731588363647 340\n","loss/train_loss 1.7775744199752808 350\n","loss/train_loss 1.7647831439971924 360\n","loss/train_loss 1.624089002609253 370\n","validation\n","50\n","100\n","150\n","200\n","250\n","loss/val_loss 1.0698505427837373 371\n","Overall Acc: \t 0.9042877531338411\n","val_metrics/Overall Acc: \t 0.9042877531338411 371\n","Mean Acc : \t 0.5614440938817097\n","val_metrics/Mean Acc : \t 0.5614440938817097 371\n","FreqW Acc : \t 0.8382477859556491\n","val_metrics/FreqW Acc : \t 0.8382477859556491 371\n","Mean IoU : \t 0.46645055289417653\n","val_metrics/Mean IoU : \t 0.46645055289417653 371\n","val_metrics/cls_0 0.9522586159164924 371\n","val_metrics/cls_1 0.6782168725968245 371\n","val_metrics/cls_2 0.8225026265753708 371\n","val_metrics/cls_3 0.2616080159471162 371\n","val_metrics/cls_4 0.2696531474962502 371\n","val_metrics/cls_5 0.36726263891378147 371\n","val_metrics/cls_6 0.2609813240932621 371\n","val_metrics/cls_7 0.4699755385246405 371\n","val_metrics/cls_8 0.8518492099853925 371\n","val_metrics/cls_9 0.41274376454064987 371\n","val_metrics/cls_10 0.8933675861282516 371\n","val_metrics/cls_11 0.5661009157939499 371\n","val_metrics/cls_12 0.06044830456352669 371\n","val_metrics/cls_13 0.855553977232698 371\n","val_metrics/cls_14 0.025337669550272668 371\n","val_metrics/cls_15 0.386768590346587 371\n","val_metrics/cls_16 0.2052315836701804 371\n","val_metrics/cls_17 0.02324310047235582 371\n","val_metrics/cls_18 0.49945702264175207 371\n","loss/train_loss 2.1571943759918213 10\n","loss/train_loss 1.739189863204956 20\n","loss/train_loss 2.1613378524780273 30\n","loss/train_loss 1.9929094314575195 40\n","loss/train_loss 1.9862040281295776 50\n","loss/train_loss 2.042489528656006 60\n","loss/train_loss 1.5080294609069824 70\n","loss/train_loss 1.9721362590789795 80\n","loss/train_loss 1.8562190532684326 90\n","loss/train_loss 1.8664815425872803 100\n","loss/train_loss 1.7642468214035034 110\n","loss/train_loss 1.941124439239502 120\n","loss/train_loss 1.8673771619796753 130\n","loss/train_loss 1.9484694004058838 140\n","loss/train_loss 1.7962068319320679 150\n","loss/train_loss 1.7835241556167603 160\n","loss/train_loss 1.94584321975708 170\n","loss/train_loss 2.1140284538269043 180\n","loss/train_loss 1.8389791250228882 190\n","loss/train_loss 1.7731497287750244 200\n","loss/train_loss 1.8273258209228516 210\n","loss/train_loss 1.8803104162216187 220\n","loss/train_loss 1.7340528964996338 230\n","loss/train_loss 1.706968903541565 240\n","loss/train_loss 2.26015567779541 250\n","loss/train_loss 1.714219570159912 260\n","loss/train_loss 1.6596643924713135 270\n","loss/train_loss 1.9878703355789185 280\n","loss/train_loss 1.9817544221878052 290\n","loss/train_loss 2.1652207374572754 300\n","loss/train_loss 2.007575511932373 310\n","loss/train_loss 1.7385565042495728 320\n","loss/train_loss 1.7602338790893555 330\n","loss/train_loss 1.9314537048339844 340\n","loss/train_loss 1.9244835376739502 350\n","loss/train_loss 1.7182960510253906 360\n","loss/train_loss 1.6509652137756348 370\n","validation\n","50\n","100\n","150\n","200\n","250\n","loss/val_loss 1.1241654200553894 371\n","Overall Acc: \t 0.9107628908450504\n","val_metrics/Overall Acc: \t 0.9107628908450504 371\n","Mean Acc : \t 0.5521700369685217\n","val_metrics/Mean Acc : \t 0.5521700369685217 371\n","FreqW Acc : \t 0.8455020393837189\n","val_metrics/FreqW Acc : \t 0.8455020393837189 371\n","Mean IoU : \t 0.46221761919062254\n","val_metrics/Mean IoU : \t 0.46221761919062254 371\n","val_metrics/cls_0 0.9517348098701891 371\n","val_metrics/cls_1 0.6705915244805467 371\n","val_metrics/cls_2 0.8468937515483852 371\n","val_metrics/cls_3 0.20559885171467338 371\n","val_metrics/cls_4 0.27584353316427335 371\n","val_metrics/cls_5 0.37457350893816005 371\n","val_metrics/cls_6 0.16714426772873417 371\n","val_metrics/cls_7 0.4837654199908093 371\n","val_metrics/cls_8 0.8633489795968685 371\n","val_metrics/cls_9 0.49027695002650634 371\n","val_metrics/cls_10 0.9088529495640275 371\n","val_metrics/cls_11 0.5739668638275055 371\n","val_metrics/cls_12 0.048382173306170784 371\n","val_metrics/cls_13 0.8519576597521497 371\n","val_metrics/cls_14 0.08344424032553213 371\n","val_metrics/cls_15 0.2154706527343471 371\n","val_metrics/cls_16 0.21608209438809717 371\n","val_metrics/cls_17 0.0044132353873997405 371\n","val_metrics/cls_18 0.5497932982774525 371\n","loss/train_loss 2.004798412322998 10\n","loss/train_loss 1.6485702991485596 20\n","loss/train_loss 2.3191447257995605 30\n","loss/train_loss 1.7981778383255005 40\n","loss/train_loss 1.823988914489746 50\n","loss/train_loss 2.0989766120910645 60\n","loss/train_loss 1.8897264003753662 70\n","loss/train_loss 1.7004289627075195 80\n","loss/train_loss 1.9823920726776123 90\n","loss/train_loss 1.8288393020629883 100\n","loss/train_loss 1.8448511362075806 110\n","loss/train_loss 1.898519515991211 120\n","loss/train_loss 1.7530968189239502 130\n","loss/train_loss 1.6871532201766968 140\n","loss/train_loss 1.8159960508346558 150\n","loss/train_loss 1.5609450340270996 160\n","loss/train_loss 1.767486333847046 170\n","loss/train_loss 2.014704704284668 180\n","loss/train_loss 1.9243861436843872 190\n","loss/train_loss 1.7773921489715576 200\n","loss/train_loss 1.8281692266464233 210\n","loss/train_loss 1.9651527404785156 220\n","loss/train_loss 1.7061192989349365 230\n","loss/train_loss 1.5919804573059082 240\n","loss/train_loss 1.9810805320739746 250\n","loss/train_loss 1.8823127746582031 260\n","loss/train_loss 1.6398789882659912 270\n","loss/train_loss 1.8903899192810059 280\n","loss/train_loss 2.471306324005127 290\n","loss/train_loss 2.0083563327789307 300\n","loss/train_loss 1.7275724411010742 310\n","loss/train_loss 1.8858041763305664 320\n","loss/train_loss 1.8954551219940186 330\n","loss/train_loss 1.6972649097442627 340\n","loss/train_loss 1.9428882598876953 350\n","loss/train_loss 1.8304316997528076 360\n","loss/train_loss 1.6888883113861084 370\n","validation\n","50\n","100\n","150\n","200\n","250\n","loss/val_loss 1.115529298067093 371\n","Overall Acc: \t 0.9053467165153308\n","val_metrics/Overall Acc: \t 0.9053467165153308 371\n","Mean Acc : \t 0.5363994011495103\n","val_metrics/Mean Acc : \t 0.5363994011495103 371\n","FreqW Acc : \t 0.8355980482932687\n","val_metrics/FreqW Acc : \t 0.8355980482932687 371\n","Mean IoU : \t 0.4526192219794217\n","val_metrics/Mean IoU : \t 0.4526192219794217 371\n","val_metrics/cls_0 0.9407362374947871 371\n","val_metrics/cls_1 0.6167134493672151 371\n","val_metrics/cls_2 0.8421026346394853 371\n","val_metrics/cls_3 0.15244605949300485 371\n","val_metrics/cls_4 0.31476613608424436 371\n","val_metrics/cls_5 0.39043274215411694 371\n","val_metrics/cls_6 0.21206573666909162 371\n","val_metrics/cls_7 0.48380854321387845 371\n","val_metrics/cls_8 0.8647864630050236 371\n","val_metrics/cls_9 0.4126411113405521 371\n","val_metrics/cls_10 0.9086649441071762 371\n","val_metrics/cls_11 0.5450970836212061 371\n","val_metrics/cls_12 0.048987904055206956 371\n","val_metrics/cls_13 0.8304725043071195 371\n","val_metrics/cls_14 0.005628297745856978 371\n","val_metrics/cls_15 0.38914648906402804 371\n","val_metrics/cls_16 0.11248727045760652 371\n","val_metrics/cls_17 0.00781689844679503 371\n","val_metrics/cls_18 0.5209647123426175 371\n","loss/train_loss 1.8194986581802368 10\n","loss/train_loss 1.6971518993377686 20\n","loss/train_loss 1.7637150287628174 30\n","loss/train_loss 1.6938202381134033 40\n","loss/train_loss 2.0396766662597656 50\n","loss/train_loss 1.9363112449645996 60\n","loss/train_loss 1.80828857421875 70\n","loss/train_loss 1.6983692646026611 80\n","loss/train_loss 2.0333454608917236 90\n","loss/train_loss 1.912549614906311 100\n","loss/train_loss 1.7666783332824707 110\n","loss/train_loss 1.9302701950073242 120\n","loss/train_loss 1.801195740699768 130\n","loss/train_loss 1.5506131649017334 140\n","loss/train_loss 2.2606754302978516 150\n","loss/train_loss 1.6138567924499512 160\n","loss/train_loss 2.155179977416992 170\n","loss/train_loss 2.03723406791687 180\n","loss/train_loss 1.7312006950378418 190\n","loss/train_loss 1.8331987857818604 200\n","loss/train_loss 1.6359219551086426 210\n","loss/train_loss 2.2402291297912598 220\n","loss/train_loss 1.659435749053955 230\n","loss/train_loss 1.9059780836105347 240\n","loss/train_loss 1.9328862428665161 250\n","loss/train_loss 1.9000871181488037 260\n","loss/train_loss 1.7207627296447754 270\n","loss/train_loss 1.9611148834228516 280\n","loss/train_loss 2.0252790451049805 290\n","loss/train_loss 2.0132594108581543 300\n","loss/train_loss 1.7719255685806274 310\n","loss/train_loss 1.8726990222930908 320\n","loss/train_loss 1.9582182168960571 330\n","loss/train_loss 1.8569581508636475 340\n","loss/train_loss 1.7557508945465088 350\n","loss/train_loss 1.8202855587005615 360\n","loss/train_loss 1.9078881740570068 370\n","validation\n","50\n","100\n","150\n","200\n","250\n","loss/val_loss 1.1163938262462616 371\n","Overall Acc: \t 0.8983416669148532\n","val_metrics/Overall Acc: \t 0.8983416669148532 371\n","Mean Acc : \t 0.549133922208949\n","val_metrics/Mean Acc : \t 0.549133922208949 371\n","FreqW Acc : \t 0.8266482248086857\n","val_metrics/FreqW Acc : \t 0.8266482248086857 371\n","Mean IoU : \t 0.4524926011769452\n","val_metrics/Mean IoU : \t 0.4524926011769452 371\n","val_metrics/cls_0 0.9317859397413749 371\n","val_metrics/cls_1 0.611280258498722 371\n","val_metrics/cls_2 0.8270052786781372 371\n","val_metrics/cls_3 0.19945407493006376 371\n","val_metrics/cls_4 0.3148812991727431 371\n","val_metrics/cls_5 0.3113862398443217 371\n","val_metrics/cls_6 0.26447247294125326 371\n","val_metrics/cls_7 0.4530474932046452 371\n","val_metrics/cls_8 0.8573514109274157 371\n","val_metrics/cls_9 0.36377721844449884 371\n","val_metrics/cls_10 0.89896386191674 371\n","val_metrics/cls_11 0.565951201382014 371\n","val_metrics/cls_12 0.14570291836685104 371\n","val_metrics/cls_13 0.8422619713065757 371\n","val_metrics/cls_14 0.011269739690188033 371\n","val_metrics/cls_15 0.2502593972711816 371\n","val_metrics/cls_16 0.20040073003104186 371\n","val_metrics/cls_17 0.0066202227306490745 371\n","val_metrics/cls_18 0.5414876932835415 371\n"]}],"source":["st = glob_st = time.time()\n","flag = False\n","for epoch_id in range(start_epoch, local_max_epoch):\n","    for images, labels in dl:\n","        it += 1\n","        start_ts = time.time()\n","        \n","        model.train()\n","\n","        images = images.to(device)\n","        labels = labels.to(device)\n","        labels = torch.squeeze(labels, 1)\n"," \n","        optim.zero_grad()\n","\n","        out_main, out_detail = model(images)\n"," \n","        loss_ffm = criteria_ffm(out_main, labels)\n","        \n","        boundery_bce, boundery_dice = boundary_loss_func(out_detail, labels)\n","\n","        boundery_bce_loss = boundery_bce\n","        boundery_dice_loss = boundery_dice\n","\n","        loss = loss_ffm + boundery_bce_loss + boundery_dice_loss\n","\n","        loss.backward()\n","        optim.step()\n","\n","        loss_avg.append(loss.item())\n","\n","        loss_boundery_bce.append(boundery_bce_loss.item())\n","        loss_boundery_dice.append(boundery_dice_loss.item())\n","\n","        if (it + 1) % print_interval == 0:\n","            loss_avg = sum(loss_avg) / len(loss_avg)\n","            lr = optim.lr\n","            ed = time.time()\n","            t_intv, glob_t_intv = ed - st, ed - glob_st\n","            eta = int((max_iter - it) * (glob_t_intv / it))\n","            eta = str(timedelta(seconds=eta))\n","\n","            loss_boundery_bce_avg = sum(loss_boundery_bce) / len(loss_boundery_bce)\n","            loss_boundery_dice_avg = sum(loss_boundery_dice) / len(loss_boundery_dice)\n","            msg = ', '.join([\n","                'epoch: {epoch}/{max_epoch}'\n","                'it: {it}/{max_it}',\n","                'lr: {lr:4f}',\n","                'loss: {loss:.4f}',\n","                'boundery_bce_loss: {boundery_bce_loss:.4f}',\n","                'boundery_dice_loss: {boundery_dice_loss:.4f}',\n","                'eta: {eta}',\n","                'time: {time:.4f}',\n","            ]).format(\n","                epoch = epoch_id,\n","                max_epoch = max_epoch,\n","                it = it+1,\n","                max_it = epoch_iteration,\n","                lr = lr,\n","                loss = loss_avg,\n","                boundery_bce_loss = loss_boundery_bce_avg,\n","                boundery_dice_loss = loss_boundery_dice_avg,\n","                time = t_intv,\n","                eta = eta\n","            )\n","            \n","            logger.info(msg)\n","            print(\"loss/train_loss\", loss.item(), it + 1)\n","            loss_avg = []\n","            loss_boundery_bce = []\n","            loss_boundery_dice = []\n","            st = ed\n","\n","        if ((it + 1) % val_interval == 0 and it + 10 < epoch_iteration) or (it + 1) % epoch_iteration == 0:\n","            print('validation')\n","            torch.cuda.empty_cache()\n","            model.eval()\n","            loss_all = 0\n","            loss_n = 0\n","            with torch.no_grad():\n","                for i_val, (images_val, labels_val) in enumerate(dlval):\n","                    if (i_val + 1) % 50 == 0:\n","                        print(i_val + 1)\n","\n","                    images_val = images_val.to(device)\n","                    labels_val = labels_val.to(device)\n","                    labels_val = torch.squeeze(labels_val, 1)\n","\n","                    outputs = model(images_val)[0]\n","                    val_loss = criteria_val(outputs, labels_val)\n","\n","                    pred = outputs.data.max(1)[1].cpu().numpy()\n","                    gt = labels_val.data.cpu().numpy()\n","\n","                    running_metrics_val.update(gt, pred)\n","                    val_loss_meter.update(val_loss.item())\n","\n","            print(\"loss/val_loss\", val_loss_meter.avg, it + 1)\n","            logger.info(\"Epoch %3d Iter %d Val Loss: %.4f\" % (epoch_id, it + 1, val_loss_meter.avg))\n","\n","            score, class_iou = running_metrics_val.get_scores()\n","            for k, v in score.items():\n","                print(k, v)\n","                logger.info(\"{}: {}\".format(k, v))\n","                print(\"val_metrics/{}\".format(k), v, it+ 1)\n","\n","            for k, v in class_iou.items():\n","                logger.info(\"{}: {}\".format(k, v))\n","                print(\"val_metrics/cls_{}\".format(k), v, it+ 1)\n","\n","            val_loss_meter.reset()\n","            running_metrics_val.reset()\n","\n","            state = {\n","                    \"epoch\": epoch_id,\n","                    \"iteration\": it+ 1,\n","                    \"model_state\": model.state_dict(),\n","                    \"optimizer_state\": optim.get_state(),\n","            }\n","            save_path = os.path.join(\n","                writer.file_writer.get_logdir(),\n","                \"{}_{}_checkpoint.pkl\".format(model_arch, cfg_data['dataset']),\n","            )\n","            torch.save(state, save_path)\n","\n","            if score[\"Mean IoU : \\t\"] >= best_iou:\n","                best_iou = score[\"Mean IoU : \\t\"]\n","                state = {\n","                    \"epoch\": epoch_id,\n","                    \"iteration\":it+ 1,\n","                    \"model_state\": model.state_dict(),\n","                    \"best_iou\": best_iou,\n","                }\n","                save_path = os.path.join(\n","                    writer.file_writer.get_logdir(),\n","                    \"{}_{}_best_model.pkl\".format(model_arch, cfg_data['dataset']),\n","                )\n","                torch.save(state, save_path)\n","            torch.cuda.empty_cache()\n","    it = 0"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"RH8UeQwnQlgY"},"outputs":[],"source":["# with torch.no_grad():\n","#     for (images_val, labels_val, _) in valloader:\n","#         images_val = images_val.to(device)\n","#         labels_val = labels_val.to(device)\n","\n","#         outputs = model(images_val)\n","#         outputs = output_val_upsample(outputs)\n","#         val_loss = loss_fn(input=outputs, target=labels_val)\n","\n","#         pred = outputs.data.max(1)[1].cpu().numpy()\n","#         gt = labels_val.data.cpu().numpy()\n","\n","#         running_metrics_val.update(gt, pred)\n","#         val_loss_meter.update(val_loss.item())\n","\n","# writer.add_scalar(\"loss/val_loss\", val_loss_meter.avg, i + 1)\n","# logger.info(\"Iter %d Val Loss: %.4f\" % (i + 1, val_loss_meter.avg))\n","\n","# score, class_iou = running_metrics_val.get_scores()"]}],"metadata":{"accelerator":"GPU","colab":{"collapsed_sections":[],"name":"STDC_dilated_3319.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}